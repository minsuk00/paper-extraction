{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi\",\n",
    "    },\n",
    "]\n",
    "\n",
    "model = \"gpt-35-turbo\"\n",
    "client = openai.AzureOpenAI(\n",
    "    api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "    api_version=os.environ.get(\"API_VERSION\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mAzureOpenAI(\n\u001b[1;32m     18\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     19\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     20\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# response_format={\"type\": \"json_object\"},\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/http_proxy.py:289\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    280\u001b[0m connect_headers \u001b[38;5;241m=\u001b[39m merge_headers(\n\u001b[1;32m    281\u001b[0m     [(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHost\u001b[39m\u001b[38;5;124m\"\u001b[39m, target), (\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/*\u001b[39m\u001b[38;5;124m\"\u001b[39m)], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_headers\n\u001b[1;32m    282\u001b[0m )\n\u001b[1;32m    283\u001b[0m connect_request \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    284\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONNECT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     url\u001b[38;5;241m=\u001b[39mconnect_url,\n\u001b[1;32m    286\u001b[0m     headers\u001b[38;5;241m=\u001b[39mconnect_headers,\n\u001b[1;32m    287\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    288\u001b[0m )\n\u001b[0;32m--> 289\u001b[0m connect_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_request\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect_response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m connect_response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[1;32m    294\u001b[0m     reason_bytes \u001b[38;5;241m=\u001b[39m connect_response\u001b[38;5;241m.\u001b[39mextensions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreason_phrase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper-extraction/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        # \"content\": \"MY NAME IS MINSUK. remember this. I will ask again.\",\n",
    "        \"content\": \"What is my name?\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     # \"content\": \"MY NAME IS MINSUK. remember this. I will ask again.\",\n",
    "    #     \"content\": \"What is my name?\",\n",
    "    # },\n",
    "]\n",
    "model = \"gpt-35-turbo\"\n",
    "client = openai.AzureOpenAI(\n",
    "    api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "    api_version=os.environ.get(\"API_VERSION\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_llm(\n",
    "    input_file: str,\n",
    "    prompt_file: str = \"../llm_prompt.txt\",\n",
    "    # num_chunks: int = -1,\n",
    "    max_tokens: int = 2000,\n",
    "    model_token_limit: int = 4096,\n",
    "):\n",
    "    model = \"gpt-3.5-turbo\"\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    input = get_string_from_text_file(input_file)\n",
    "    # prompt = get_string_from_text_file(prompt_file) + input + \"```\"\n",
    "    prompt = get_string_from_text_file(prompt_file)\n",
    "    # Encode the text_data into token integers\n",
    "    token_integers = tokenizer.encode(input)\n",
    "\n",
    "    # Split the token integers into chunks based on max_tokens\n",
    "    # chunk_size = max_tokens - len(token_integers)\n",
    "    # if num_chunks != -1:\n",
    "    #     chunk_size = len(token_integers) // num_chunks\n",
    "    # else:\n",
    "    #     chunk_size = model_token_limit - 50\n",
    "    chunks = [\n",
    "        token_integers[i : i + max_tokens]\n",
    "        for i in range(0, len(token_integers), max_tokens)\n",
    "    ]\n",
    "    # print(\"chunk size:\", max_tokens)\n",
    "\n",
    "    # Decode token chunks back to strings\n",
    "    chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "    print(f\"{len(chunks)} chunks processing...\")\n",
    "\n",
    "    responses = []\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"To provide the context for the above prompt, I will send you text in parts. When I am finished, I will tell you 'ALL PARTS SENT'. Do NOT answer until you have received all the parts. You will be penalized otherwise.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        messages.append({\"role\": \"user\", \"content\": chunk})\n",
    "\n",
    "        # Check if total tokens exceed the model's limit and remove oldest chunks if necessary\n",
    "        while (\n",
    "            sum(len(tokenizer.encode(msg[\"content\"])) for msg in messages)\n",
    "            > model_token_limit\n",
    "        ):\n",
    "            messages.pop(1)  # Remove the oldest chunk\n",
    "\n",
    "        # client = LLM(\"../llm_prompt.txt\", base=\"azure\", use_model=\"gpt3\")\n",
    "        # client.prompt = \"\\n\".join([message[\"content\"] for message in messages])\n",
    "        # response = client.get_response()\n",
    "        # responses.append(response)\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=messages\n",
    "        )\n",
    "        # chatgpt_response = response.choices[0].message[\"content\"].strip()\n",
    "        chatgpt_response = response.choices[0].message.content\n",
    "        responses.append(chatgpt_response)\n",
    "        print(f\"{i}th chunk processed {responses}\")\n",
    "\n",
    "    # Add the final \"ALL PARTS SENT\" message\n",
    "    messages.append({\"role\": \"user\", \"content\": \"```\\nALL PARTS SENT\"})\n",
    "    # client = LLM(\"../llm_prompt.txt\", base=\"azure\", use_model=\"gpt3\")\n",
    "    # client.prompt = \"\\n\".join([message[\"content\"] for message in messages])\n",
    "    # response = client.get_response()\n",
    "    # responses.append(response)\n",
    "    response = openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    # final_response = response.choices[0].message[\"content\"].strip()\n",
    "    final_response = response.choices[0].message.content\n",
    "    responses.append(final_response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../text/3D Convolutional Neural Networks for Human Action Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ../llm_prompt.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "9047 tokens\n",
      "2 chunks processing...\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "{\n",
      "  \"filename\": \"Not specified\",\n",
      "  \"extracted-section-list\":\"Not specified\",\n",
      "  \"target-section-extraction-result\": {\n",
      "      \"introduction\":{\n",
      "        \"extracted-text\": \"Not specified\"\n",
      "      },\n",
      "      \"method\":{\n",
      "        \"extracted-text\": \"2. 3D Convolutional Neural Networks\\nIn 2D CNNs, 2D convolution is performed at the convolutional layers to extract features from local neighborhood on feature maps in the previous layer. Then an additive bias is applied and the result is passed through a sigmoid function. Formally, the value of unit at position ( x, y) in the jth feature map in the ith layer, denoted as vxyij, is given by vxyij= tanh(bij+∑mPi−1∑p=0Qi−1∑q=0wpqijmv(x+p)(y+q)(i−1)m), where tanh( ·) is the hyperbolic tangent function, bij is the bias for this feature map, mindexes over the set of feature maps in the ( i−1)th layer connected to the current feature map, wpqijkis the value at the position ( p, q) of the kernel connected to the kth feature map, and PiandQiare the height and width of the kernel, respectively. In the subsampling layers, the resolution of the feature maps is reduced by pooling over local neighborhood on the feature maps in the previous layer, thereby increasing invariance to distortions on the inputs. A CNN architecture can be constructed by stacking multiple layers of convolution and subsampling in an alternating fashion. The parameters of CNN, such as the bias bijand the kernel weight wpqijk, are usually trained using either supervised or unsupervised approaches ( LeCun et al. ,1998; Ranzato et al. ,2007).\\n2.1. 3D Convolution\\nIn 2D CNNs, convolutions are applied on the 2D feature maps to compute features from the spatial dimensions only. When applied to video analysis problems, it is desirable to capture the motion information encoded in multiple contiguous frames. To this end, we propose to perform 3D convolutions in the convolution stages of CNNs to compute features from both spatial and temporal dimensions. The 3D convolution is achieved by convolving a 3D kernel to the cube formed by stacking multiple contiguous frames together. By this construction, the feature maps in the convolution layer is connected to multiple contiguous frames in the previous layer, thereby capturing motion information. Formally, the value at position ( x, y, z ) on the jth feature map in the ith layer is given by vxyzij=tanh(bij+∑mPi−1∑p=0Qi−1∑q=0Ri−1∑r=0wpqrijmv(x+p)(y+q)(z+r)(i−1)m), where Riis the size of the 3D kernel along the temporal dimension, wpqrijmis the ( p, q, r)th value of the kernel connected to the mth feature map in the previous layer. A comparison of 2D and 3D convolutions is given in Figure 1.\\n2.2. A 3D CNN Architecture\\nBased on the 3D convolution described above, a variety of CNN architectures can be devised. In the following, we describe a 3D CNN architecture that we have developed for human action recognition on the TRECVID data set. In this architecture shown in Figure 3, we consider 7 frames of size 60 ×40 centered on the current frame as inputs to the 3D CNN model. We first apply a set of hardwired kernels to generate multiple channels of information from the input frames. This results in 33 feature maps in the second layer in 5 different channels known as gray, gradient-x, gradient-y, optflow-x, and optflow-y. The gray channel contains the gray pixel values of the 7 input frames. The feature maps in the gradient-x and gradient-y channels are obtained by computing gradients along the horizontal and vertical directions, respectively, on each of the 7 input frames, and the optflow-x and optflow-y channels contain the optical flow fields, along the horizontal and vertical directions, respectively, computed from adjacent input frames. This hardwired layer is used to encode our prior knowledge on features, and this scheme usually leads to better performance as c\"\n",
      "      },\n",
      "      \"result\":{\n",
      "        \"extracted-text\": \"Not specified\"\n",
      "      },\n",
      "      \"conclusion\":{\n",
      "        \"extracted-text\": \"Not specified\"\n",
      "      },\n",
      "   \"unknown-sections\": \"Not specified\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def apply_llm(\n",
    "    max_tokens_per_chunk: int = 3500,\n",
    "    model_token_limit: int = 8192,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    input = get_string_from_text_file(\n",
    "        \"../text/3D Convolutional Neural Networks for Human Action Recognition.txt\"\n",
    "    )\n",
    "    system_prompt = get_string_from_text_file(\"../llm_prompt.txt\")\n",
    "    # text = input + prompt\n",
    "    text = input\n",
    "    token_integers = tokenizer.encode(text)\n",
    "\n",
    "    print(len(token_integers), \"tokens\")\n",
    "\n",
    "    num_chunks = -(-len(token_integers) // max_tokens_per_chunk)\n",
    "    chunks = []\n",
    "    print(f\"{num_chunks} chunks processing...\")\n",
    "    for i in range(num_chunks):\n",
    "        start = i * max_tokens_per_chunk\n",
    "        end = min((i + 1) * max_tokens_per_chunk, len(text))\n",
    "\n",
    "        chunk = \"\"\n",
    "        decoded_chunk = tokenizer.decode(token_integers[start:end])\n",
    "        if i == num_chunks - 1:\n",
    "            chunk += (\n",
    "                f\"[START PART {i + 1}/{num_chunks}]\\n\"\n",
    "                + text[start:end]\n",
    "                + f\"\\n[END PART {i + 1}/{num_chunks}]\"\n",
    "            )\n",
    "            chunk += \"\\nALL PARTS SENT. Now you can continue processing the request according to the Instruction.\"\n",
    "        else:\n",
    "            chunk += (\n",
    "                f'Do not answer yet. This is just another part of the text I want to send you. Just receive and acknowledge as \"Part {i + 1}/{num_chunks} received\" and wait for the next part.\\n[START PART {i + 1}/{num_chunks}]\\n'\n",
    "                + decoded_chunk\n",
    "                + f\"\\n[END PART {i + 1}/{num_chunks}]\"\n",
    "            )\n",
    "            chunk += f'\\nRemember not answering yet. Just acknowledge you received this part with the message \"Part {i + 1}/{num_chunks} received\" and wait for the next part.'\n",
    "\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    # model = \"gpt-35-turbo\"\n",
    "    # model = \"gpt-35-turbo-16k\"\n",
    "    model = \"gpt-4\"\n",
    "    client = openai.AzureOpenAI(\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "        api_version=os.environ.get(\"API_VERSION\"),\n",
    "        azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    "    )\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # client = LLM(\"../llm_prompt.txt\", base=\"azure\", use_model=\"gpt3\")\n",
    "        # client.prompt = chunk\n",
    "        # response = client.get_response(max_tokens=1000)\n",
    "        # responses.append(response)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": chunk,\n",
    "            },\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        responses.append(response)\n",
    "        if verbose:\n",
    "            print(response)\n",
    "\n",
    "    # print(responses)\n",
    "\n",
    "\n",
    "res = apply_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../text/3D Convolutional Neural Networks for Human Action Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ../llm_prompt.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "9047 tokens\n",
      "3 chunks processing...\n",
      "{\n",
      "  \"filename\": \"3D Convolutional Neural Networks for Human Action Recognition\",\n",
      "  \"extracted-section-list\": [],\n",
      "  \"target-section-extraction-result\": {\n",
      "      \"introduction\":{\n",
      "        \"start-index\": null,\n",
      "        \"end-index\": null\n",
      "      },\n",
      "      \"method\":{\n",
      "        \"start-index\": null,\n",
      "        \"end-index\": null\n",
      "      },\n",
      "      \"result\":{\n",
      "        \"start-index\": null,\n",
      "        \"end-index\": null\n",
      "      },\n",
      "      \"conclusion\":{\n",
      "        \"start-index\": null,\n",
      "        \"end-index\": null\n",
      "      }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"filename\": \"3D Convolutional Neural Networks for Human Action Recognition\",\n",
      "  \"extracted-section-list\": [\"Introduction\", \"Method\", \"Result\"],\n",
      "  \"target-section-extraction-result\": {\n",
      "      \"introduction\":{\n",
      "        \"start-index\": 0,\n",
      "        \"end-index\": 136\n",
      "      },\n",
      "      \"method\":{\n",
      "        \"start-index\": 137,\n",
      "        \"end-index\": 283\n",
      "      },\n",
      "      \"result\":{\n",
      "        \"start-index\": 284,\n",
      "        \"end-index\": 348\n",
      "```\n",
      "\"conclusion\":{\n",
      "        \"start-index\": null,\n",
      "        \"end-index\": null\n",
      "      }\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def apply_llm(\n",
    "    max_tokens_per_chunk: int = 3400,\n",
    "    model_token_limit: int = 8192,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    input = get_string_from_text_file(\n",
    "        \"../text/3D Convolutional Neural Networks for Human Action Recognition.txt\"\n",
    "    )\n",
    "    system_prompt = get_string_from_text_file(\"../llm_prompt.txt\")\n",
    "    # text = input + prompt\n",
    "    text = input\n",
    "    token_integers = tokenizer.encode(text)\n",
    "\n",
    "    print(len(token_integers), \"tokens\")\n",
    "\n",
    "    num_chunks = -(-len(token_integers) // max_tokens_per_chunk)\n",
    "    chunks = []\n",
    "    print(f\"{num_chunks} chunks processing...\")\n",
    "    for i in range(num_chunks):\n",
    "        start = i * max_tokens_per_chunk\n",
    "        end = min((i + 1) * max_tokens_per_chunk, len(token_integers))\n",
    "\n",
    "        chunk = \"\"\n",
    "        decoded_chunk = tokenizer.decode(token_integers[start:end])\n",
    "        chunk += (\n",
    "            f\"[START PART {i + 1}/{num_chunks}. STARTING TOKEN INDEX: {start}]\\n\"\n",
    "            + decoded_chunk\n",
    "            + f\"\\n[END PART {i + 1}/{num_chunks}. ENDING TOKEN INDEX: {end}]\"\n",
    "        )\n",
    "\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    model = \"gpt-35-turbo\"\n",
    "    # model = \"gpt-35-turbo-16k\"\n",
    "    # model = \"gpt-4\"\n",
    "    client = openai.AzureOpenAI(\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "        api_version=os.environ.get(\"API_VERSION\"),\n",
    "        azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    "    )\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # client = LLM(\"../llm_prompt.txt\", base=\"azure\", use_model=\"gpt3\")\n",
    "        # client.prompt = chunk\n",
    "        # response = client.get_response(max_tokens=1000)\n",
    "        # responses.append(response)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\n\" + chunk + \"\\n```\\n\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Output so far:\\n```\\n\" + responses[-1] + \"\\n```\\n\"\n",
    "                    if i != 0\n",
    "                    else \"no output so far\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            # response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        responses.append(response)\n",
    "        if verbose:\n",
    "            # print(chunk)\n",
    "            print(response)\n",
    "\n",
    "    return responses[-1]\n",
    "    # print(responses)\n",
    "\n",
    "\n",
    "res = apply_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../text/3D Convolutional Neural Networks for Human Action Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ../llm_prompt.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "9047 tokens\n",
      "23 chunks processing...\n",
      "prev: None\n",
      "new: Introduction\n",
      "-------\n",
      "prev: Introduction\n",
      "new: Method\n",
      "-------\n",
      "prev: Method\n",
      "new: Result\n",
      "-------\n",
      "prev: Result\n",
      "new: None\n",
      "-------\n",
      "prev: None\n",
      "new: Related Work\n",
      "-------\n",
      "prev: Related Work\n",
      "new: Conclusion\n",
      "-------\n",
      "prev: Conclusion\n",
      "new: None\n",
      "-------\n",
      "All possible sections found. Exiting loop... chunk no.12\n"
     ]
    }
   ],
   "source": [
    "# chunk classification\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def apply_llm(\n",
    "    max_tokens_per_chunk: int = 400,\n",
    "    # model_token_limit: int = 8192,\n",
    "    model_token_limit: int = 4096,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    paper_data = get_string_from_text_file(\n",
    "        \"../text/3D Convolutional Neural Networks for Human Action Recognition.txt\"\n",
    "    )\n",
    "    prompt = get_string_from_text_file(\"../llm_prompt.txt\")\n",
    "    token_integers = tokenizer.encode(paper_data)\n",
    "\n",
    "    print(len(token_integers), \"tokens\")\n",
    "\n",
    "    num_chunks = -(-len(token_integers) // max_tokens_per_chunk)\n",
    "    chunks = []\n",
    "    print(f\"{num_chunks} chunks processing...\")\n",
    "    for i in range(num_chunks):\n",
    "        start = i * max_tokens_per_chunk\n",
    "        end = min((i + 1) * max_tokens_per_chunk, len(token_integers))\n",
    "\n",
    "        chunk = \"\"\n",
    "        decoded_chunk = tokenizer.decode(token_integers[start:end])\n",
    "        # chunk += (\n",
    "        #     f\"[START PART {i + 1}/{num_chunks}. STARTING TOKEN INDEX: {start}]\\n\"\n",
    "        #     + decoded_chunk\n",
    "        #     + f\"\\n[END PART {i + 1}/{num_chunks}. ENDING TOKEN INDEX: {end}]\"\n",
    "        # )\n",
    "\n",
    "        chunks.append(decoded_chunk)\n",
    "\n",
    "    responses = []\n",
    "    model = \"gpt-35-turbo\"\n",
    "    # model = \"gpt-35-turbo-16k\"\n",
    "    # model = \"gpt-4\"\n",
    "    client = openai.AzureOpenAI(\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "        api_version=os.environ.get(\"API_VERSION\"),\n",
    "        azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    "    )\n",
    "    prev_res = \"None\"\n",
    "    possible_sections = [\"Introduction\", \"Method\", \"Result\", \"Conclusion\", \"None\"]\n",
    "    output = {}\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        prompt_template = PromptTemplate.from_template(prompt)\n",
    "        msg = prompt_template.format(\n",
    "            possible_sections=possible_sections,\n",
    "            input_chunk=chunk,\n",
    "            previous_result=prev_res,\n",
    "            target_chunk_num=i,\n",
    "            total_chunk_num=num_chunks,\n",
    "        )\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": msg,\n",
    "            },\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            # response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        responses.append(response)\n",
    "        if response != \"None\":\n",
    "            output[response] = (output[response] if response in output else \"\") + chunk\n",
    "\n",
    "        if response != prev_res:\n",
    "            print(\"prev:\", prev_res)\n",
    "            print(\"new:\", response)\n",
    "            print(\"-------\")\n",
    "            if prev_res in possible_sections and prev_res != \"None\":\n",
    "                possible_sections.remove(prev_res)\n",
    "                if len(possible_sections) == 1:\n",
    "                    print(f\"All possible sections found. Exiting loop... chunk no.{i}\")\n",
    "                    break\n",
    "\n",
    "        prev_res = response\n",
    "        if verbose:\n",
    "            # print(chunk)\n",
    "            print(response)\n",
    "\n",
    "    return output\n",
    "    # print(responses)\n",
    "\n",
    "\n",
    "res = apply_llm(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from A frameshift mutation in NOD2 associated with susceptibility to Crohn's disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Updated world map of the Köppen-Geiger climate classification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A safe operating space for humanity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mutation in the α-Synuclein Gene Identified in Families with Parkinson's Disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Capacity of Multi‐antenna Gaussian Channels.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Instrumental Variables Regression with Weak Instruments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Self-Rating Depression Scale.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The representative concentration pathways: an overview.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Random effects structure for confirmatory hypothesis testing: Keep it maximal.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Homeostasis model assessment: insulin resistance and ?-cell function from fasting plasma glucose and insulin concentrations in man.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gene expression profiling predicts clinical outcome of breast cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A comparison of methods to test mediation and other intervening variable effects..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Opinion Mining and Sentiment Analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Term-weighting approaches in automatic text retrieval.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Technology Acceptance Model 3 and a Research Agenda on Interventions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Graph Neural Network Model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The human brain is intrinsically organized into dynamic, anticorrelated functional networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from AFLP: a new technique for DNA fingerprinting.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Tight blood pressure control and risk of macrovascular and microvascular complications in type 2 diabetes: UKPDS 38.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DNA methylation patterns and epigenetic memory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from General Theory of Three-Dimensional Consolidation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Elements of Statistical Learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Orthonormal bases of compactly supported wavelets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Diamond-like amorphous carbon.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Decoding by Linear Programming.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Most mammalian mRNAs are conserved targets of microRNAs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Transformation of the Nitrogen Cycle: Recent Trends, Questions, and Potential Solutions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cytoscape: A Software Environment for Integrated Models of Biomolecular Interaction Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ground State of the Electron Gas by a Stochastic Method.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Political Science and the Three New Institutionalisms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mathematical Methods of Classical Mechanics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast and robust fixed-point algorithms for independent component analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Five Misunderstandings About Case-Study Research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Association of glycaemia with macrovascular and microvascular complications of type 2 diabetes (UKPDS 35): prospective observational study.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Learning Deep Features for Discriminative Localization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Telling more than we can know: Verbal reports on mental processes..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Benefits of Frequent Positive Affect: Does Happiness Lead to Success?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Health Belief Model: A Decade Later.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from REVIGO Summarizes and Visualizes Long Lists of Gene Ontology Terms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Translating the Histone Code.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum Spin Hall Effect and Topological Phase Transition in HgTe Quantum Wells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Thumbs up?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Speech recognition with deep recurrent neural networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from UMAP: Uniform Manifold Approximation and Projection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Independent component analysis: algorithms and applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrating single-cell transcriptomic data across different conditions, technologies, and species.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Authoritative sources in a hyperlinked environment.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Scoping studies: advancing the methodology.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mastering the game of Go without human knowledge.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Going deeper with convolutions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CONSORT 2010 Explanation and Elaboration: updated guidelines for reporting parallel group randomised trials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Strong localization of photons in certain disordered dielectric superlattices.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from BEAST 2: A Software Platform for Bayesian Evolutionary Analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Temperature sensitivity of soil carbon decomposition and feedbacks to climate change.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Differential gene and transcript expression analysis of RNA-seq experiments with TopHat and Cufflinks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Avogadro: an advanced semantic chemical editor, visualization, and analysis platform.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Microenvironmental regulation of tumor progression and metastasis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE NF-κB AND IκB PROTEINS: New Discoveries and Insights.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A comprehensive review of ZnO materials and devices.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Role of AMP-activated protein kinase in mechanism of metformin action.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Genotype-Tissue Expression (GTEx) project.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Why Most Published Research Findings Are False.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Optical Coherence Tomography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bias in meta-analysis detected by a simple, graphical test.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Towards Evaluating the Robustness of Neural Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Theory of Propagation of Elastic Waves in a Fluid-Saturated Porous Solid. I. Low-Frequency Range.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fiji: an open-source platform for biological-image analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cognitive Structure of Emotions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Large Mass Hierarchy from a Small Extra Dimension.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mutational heterogeneity in cancer and the search for new cancer-associated genes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Immediate Psychological Responses and Associated Factors during the Initial Stage of the 2019 Coronavirus Disease (COVID-19) Epidemic among the General Population in China.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ERC: A Theory of Equity, Reciprocity, and Competition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Ensembl Variant Effect Predictor.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from MapReduce.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Data Mining: Practical Machine Learning Tools and Techniques.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Graphene photonics and optoelectronics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Making sense of Cronbach's alpha.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Fusiform Face Area: A Module in Human Extrastriate Cortex Specialized for Face Perception.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Data mining: concepts and techniques.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The number of people with glaucoma worldwide in 2010 and 2020.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Initial sequencing and comparative analysis of the mouse genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Research electronic data capture (REDCap)—A metadata-driven methodology and workflow process for providing translational research informatics support.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Oxidants, antioxidants, and the degenerative diseases of aging..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Conversion of 5-Methylcytosine to 5-Hydroxymethylcytosine in Mammalian DNA by MLL Partner TET1.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Probabilistic roadmaps for path planning in high-dimensional configuration spaces.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An introduction to cybernetics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Folding DNA to create nanoscale shapes and patterns.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from From inflammation to sickness and depression: when the immune system subjugates the brain.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Initial sequencing and analysis of the human genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Robust, Simple Genotyping-by-Sequencing (GBS) Approach for High Diversity Species.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Metagenomic biomarker discovery and explanation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mining association rules between sets of items in large databases.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A training algorithm for optimal margin classifiers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Prodigal: prokaryotic gene recognition and translation initiation site identification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Five Rules for the Evolution of Cooperation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Genome engineering using the CRISPR-Cas9 system.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RoB 2: a revised tool for assessing risk of bias in randomised trials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Does the autistic child have a “theory of mind” ?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cambridge Structural Database.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE PREPARATION OF 131I-LABELLED HUMAN GROWTH HORMONE OF HIGH SPECIFIC RADIOACTIVITY.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from How to share a secret.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Continuum Theory of Ductile Rupture by Void Nucleation and Growth: Part I—Yield Criteria and Flow Rules for Porous Ductile Media.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Perturbation Theory for Linear Operators.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Governing the Commons: The Evolution of Institutions for Collective Action.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The magical number 4 in short-term memory: A reconsideration of mental storage capacity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum Spin Hall Effect in Graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SSD: Single Shot MultiBox Detector.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Atoms, molecules, solids, and surfaces: Applications of the generalized gradient approximation for exchange and correlation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Human Microbiome Project.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cancer-related inflammation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inference from Iterative Simulation Using Multiple Sequences.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Extracting and composing robust features with denoising autoencoders.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Hungarian method for the assignment problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Greedy function approximation: A gradient boosting machine..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Non-Abelian anyons and topological quantum computation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Significance analysis of microarrays applied to the ionizing radiation response.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Risk, Ambiguity, and the Savage Axioms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Purification of Biologically Active Globin Messenger RNA by Chromatography on Oligothymidylic acid-Cellulose.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The quality of government.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Power-Law Distributions in Empirical Data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from WebLogo: A Sequence Logo Generator: Figure 1.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Electrophoretic transfer of proteins from polyacrylamide gels to nitrocellulose sheets: procedure and some applications..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Graph Theory with Applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from z-Tree: Zurich toolbox for ready-made economic experiments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A theoretical basis for a biopharmaceutic drug classification: the correlation of in vitro drug product dissolution and in vivo bioavailability..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Creating the CIPRES Science Gateway for inference of large phylogenetic trees.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mechanisms of post-transcriptional regulation by microRNAs: are the answers in sight?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Amber biomolecular simulation programs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Effects of noise letters upon the identification of a target letter in a nonsearch task.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Categories for the Working Mathematician.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Oligomerization and phosphorylation of the Ire1p kinase during intracellular signaling from the endoplasmic reticulum to the nucleus..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Enrichr: interactive and collaborative HTML5 gene list enrichment analysis tool.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Aggregated Residual Transformations for Deep Neural Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Item-based collaborative filtering recommendation algorithms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A finite element method for crack growth without remeshing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Analysis of protein-coding genetic variation in 60,706 humans.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Optical Coherence and Quantum Optics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from APE: Analyses of Phylogenetics and Evolution in R language.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast unfolding of communities in large networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Prejudice, social stress, and mental health in lesbian, gay, and bisexual populations: Conceptual issues and research evidence..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self-interaction correction to density-functional approximations for many-electron systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A General Framework for Analyzing Sustainability of Social-Ecological Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Experimental observation of the quantum Hall effect and Berry's phase in graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Genome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On the generators of quantum dynamical semigroups.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Robust enumeration of cell subsets from tissue expression profiles.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FreeSurfer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Velvet: Algorithms for de novo short read assembly using de Bruijn graphs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A comprehensive set of sequence analysis programs for the VAX.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RNA-Guided Human Genome Engineering via Cas9.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Single-layer MoS2 transistors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A method and server for predicting damaging missense mutations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Interpretative strategies for lung function tests.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Those Who Understand: Knowledge Growth in Teaching.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The UK Biobank resource with deep phenotyping and genomic data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Singular Value Thresholding Algorithm for Matrix Completion.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Prevalence, Severity, and Comorbidity of 12-Month DSM-IV Disorders in the National Comorbidity Survey Replication.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mixed-effects modeling with crossed random effects for subjects and items.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gene Ontology: tool for the unification of biology.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dynamic Scaling of Growing Interfaces.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from AutoDock4 and AutoDockTools4: Automated docking with selective receptor flexibility.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Collaborative meta-analysis of randomised trials of antiplatelet therapy for prevention of death, myocardial infarction, and stroke in high risk patients.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Enterotypes of the human gut microbiome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cancer Genome Atlas Pan-Cancer analysis project.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Identification and analysis of functional elements in 1% of the human genome by the ENCODE pilot project.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bagging predictors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from De novo transcript sequence reconstruction from RNA-seq using the Trinity platform for reference generation and analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Contribution to the Empirics of Economic Growth.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Introduction to the Bootstrap.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Strengthening the reporting of observational studies in epidemiology (STROBE) statement: guidelines for reporting observational studies.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Multivariate Adaptive Regression Splines.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Executive Functions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Corporate Ownership Around the World.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Why do Some Countries Produce So Much More Output Per Worker than Others?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A candidate genetic risk factor for vascular disease: a common mutation in methylenetetrahydrofolate reductase.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ImageNet classification with deep convolutional neural networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Reflective Practitioner: How Professionals Think in Action.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comparison of multiple Amber force fields and development of improved protein backbone parameters.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from UCSF Chimera—A visualization system for exploratory research and analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Investor protection and corporate governance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An introduction to ROC analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dynamic Source Routing in Ad Hoc Wireless Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Practical methods for incorporating summary time-to-event data into meta-analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FSL.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Coral Reefs Under Rapid Climate Change and Ocean Acidification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Momentum Contrast for Unsupervised Visual Representation Learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A robust and high-throughput Cre reporting and characterization system for the whole mouse brain.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Therapeutic inhibition of CXCR2 by Reparixin attenuates acute lung injury in mice..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Least squares quantization in PCM.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Theory of Bose-Einstein condensation in trapped gases.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Simultaneous Inference in General Parametric Models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Proposed Experiment to Test Local Hidden-Variable Theories.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Methods for characterization of Streptomyces species.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Designing qualitative research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The determination of the elastic field of an ellipsoidal inclusion, and related problems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Costs and Benefits of Ownership: A Theory of Vertical and Lateral Integration.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The cosmological constant problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cooling, Heating, Generating Power, and Recovering Waste Heat with Thermoelectric Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Byzantine Generals Problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A global clinical measure of fitness and frailty in elderly people.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Shape‐Controlled Synthesis of Metal Nanocrystals: Simple Chemistry Meets Complex Physics?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Finding scientific topics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Shedding light on the cell biology of extracellular vesicles.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Highly accurate protein structure prediction with AlphaFold.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Nitric Oxide and Peroxynitrite in Health and Disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Observation of Gravitational Waves from a Binary Black Hole Merger.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Community detection in graphs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The behaviour change wheel: A new method for characterising and designing behaviour change interventions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Palladium-Catalyzed Ligand-Directed C−H Functionalization Reactions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Structural Equation Models with Unobservable Variables and Measurement Error: Algebra and Statistics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Accelerated Profile HMM Searches.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Better reporting of interventions: template for intervention description and replication (TIDieR) checklist and guide.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Molecular dynamics with coupling to an external bath.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dissociable Intrinsic Connectivity Networks for Salience Processing and Executive Control.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Social Relationships and Mortality Risk: A Meta-analytic Review.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Estimating the mean and variance from the median, range, and the size of a sample.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from QUANTUM ESPRESSO: a modular and open-source software project for quantum simulations of materials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The use of partial least squares path modeling in international marketing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A relational model of data for large shared data banks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Microalgae for biodiesel production and other applications: A review.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Compressibility of Media under Extreme Pressures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global, regional, and national age–sex specific all-cause and cause-specific mortality for 240 causes of death, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from XGBoost.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Myeloid-derived suppressor cells as regulators of the immune system.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Measurement of cellulase activities.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Human gut microbiome viewed across age and geography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The large $N$ limit of superconformal field theories and supergravity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Health benefits of physical activity: the evidence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Emergence of Scaling in Random Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from AMPK and mTOR regulate autophagy through direct phosphorylation of Ulk1.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A survey on Image Data Augmentation for Deep Learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Scoping studies: towards a methodological framework.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Macroeconomics and Reality.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Optimal approximations by piecewise smooth functions and associated variational problems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Consensus and Cooperation in Networked Multi-Agent Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An analysis of 5'-noncoding sequences from 699 vertebrate messenger RNAs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The DNA-damage response in human biology and disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Electron-Hole Diffusion Lengths Exceeding 1 Micrometer in an Organometal Trihalide Perovskite Absorber.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell Sequencing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Distributed Hierarchical Processing in the Primate Cerebral Cortex.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Elliptic Partial Differential Equations of Second Order.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Postwar U.S. Business Cycles: An Empirical Investigation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Resilience and Stability of Ecological Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RoBERTa: A Robustly Optimized BERT Pretraining Approach.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Convergence of Probability Measures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Feature Pyramid Networks for Object Detection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bose-Einstein Condensation in a Gas of Sodium Atoms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from limma powers differential expression analyses for RNA-sequencing and microarray studies.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Climate and atmospheric history of the past 420,000 years from the Vostok ice core, Antarctica.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global quantification of mammalian gene expression control.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Isolation of a cDNA cLone Derived from a Blood-Borne Non-A, Non-B Viral Hepatitis Genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A rapid alkaline extraction procedure for screening recombinant plasmid DNA.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Common risk factors in the returns on stocks and bonds.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Diet rapidly and reproducibly alters the human gut microbiome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Nonlinear Component Analysis as a Kernel Eigenvalue Problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Estimating the Dimension of a Model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Power of Feedback.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global burden of hypertension: analysis of worldwide data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Basic objects in natural categories.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Stochastic Approximation Method.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Large Scale Structure of Space-Time.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Impact of Trade on Intra-Industry Reallocations and Aggregate Industry Productivity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Internet of Things (IoT): A vision, architectural elements, and future directions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Epidemic Spreading in Scale-Free Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Roll-to-roll production of 30-inch graphene films for transparent electrodes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Years lived with disability (YLDs) for 1160 sequelae of 289 diseases and injuries 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE CONSTITUTION AND FUNDAMENTAL PROPERTIES OF SOLIDS AND LIQUIDS. PART I. SOLIDS..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Raman Spectrum of Graphene and Graphene Layers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A review on buildings energy consumption information.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The adolescent brain and age-related behavioral manifestations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Biodiversity loss and its impact on humanity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Climbing the Density Functional Ladder: Nonempirical Meta–Generalized Gradient Approximation Designed for Molecules and Solids.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Social Cognitive Theory: An Agentic Perspective.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comprehensive genomic characterization defines human glioblastoma genes and core pathways.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Critical evaluation of the Newcastle-Ottawa scale for the assessment of the quality of nonrandomized studies in meta-analyses.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Anti de Sitter space and holography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Text categorization with Support Vector Machines: Learning with many relevant features.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Neurogenesis in the adult human hippocampus.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Establishing a standard definition for child overweight and obesity worldwide: international survey.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Limited Memory Algorithm for Bound Constrained Optimization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Structural absorption by barbule microstructures of super black bird of paradise feathers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Initial conditions and moment restrictions in dynamic panel data models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Minds, brains, and programs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A meta-analytic review of experiments examining the effects of extrinsic rewards on intrinsic motivation..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Classification of acute pancreatitis—2012: revision of the Atlanta classification and definitions by international consensus.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Active appearance models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Xception: Deep Learning with Depthwise Separable Convolutions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gene ontology analysis for RNA-seq: accounting for selection bias.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from New Method for High-Accuracy Determination of the Fine-Structure Constant Based on Quantized Hall Resistance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Corporate financing and investment decisions when firms have information that investors do not have.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On the variation of the initial mass function.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Endogenous Technological Change.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Topological insulators and superconductors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A new criterion for assessing discriminant validity in variance-based structural equation modeling.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Research Domain Criteria (RDoC): Toward a New Classification Framework for Research on Mental Disorders.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Identification of Herpesvirus-Like DNA Sequences in AIDS-Sssociated Kaposi's Sarcoma.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Public-Key Cryptosystems Based on Composite Degree Residuosity Classes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Upper and Lower Probabilities Induced by a Multivalued Mapping.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gefitinib or Chemotherapy for Non–Small-Cell Lung Cancer with Mutated EGFR.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Advances in functional and structural MR image analysis and implementation as FSL.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A global reference for human genetic variation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Identity-Based Encryption from the Weil Pairing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GUS fusions: beta-glucuronidase as a sensitive and versatile gene fusion marker in higher plants..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Electronics and optoelectronics of two-dimensional transition metal dichalcogenides.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cityscapes Dataset for Semantic Urban Scene Understanding.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Primary Production of the Biosphere: Integrating Terrestrial and Oceanic Components.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Trends, Rhythms, and Aberrations in Global Climate 65 Ma to Present.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Effect of potentially modifiable risk factors associated with myocardial infarction in 52 countries (the INTERHEART study): case-control study.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A haplotype map of the human genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global prevalence of dementia: a Delphi consensus study.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Resonance Absorption by Nuclear Magnetic Moments in a Solid.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Adaptive Lasso and Its Oracle Properties.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum cryptography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from MobileNetV2: Inverted Residuals and Linear Bottlenecks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Geographic Localization of Knowledge Spillovers as Evidenced by Patent Citations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Finding and evaluating community structure in networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Generalized autoregressive conditional heteroskedasticity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Welcome to the Tidyverse.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SPSS and SAS procedures for estimating indirect effects in simple mediation models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Economic Welfare and the Allocation of Resources for Invention.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Structure, function and diversity of the healthy human microbiome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Risk Aversion and Incentive Effects.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Reciprocal Relations in Irreversible Processes. I..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Autophagy fights disease through cellular self-digestion.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Model of Leptons.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Investor Psychology and Security Market Under‐ and Overreactions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self-Rated Health and Mortality: A Review of Twenty-Seven Community Studies.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Deep learning in neural networks: An overview.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rayyan—a web and mobile app for systematic reviews.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The I-TASSER Suite: protein structure and function prediction.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Content Analysis: An Introduction to its Methodology..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Development and preliminary testing of the new five-level version of EQ-5D (EQ-5D-5L).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Accurate Molecular Van Der Waals Interactions from Ground-State Electron Density and Free-Atom Reference Data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Purposeful Sampling for Qualitative Data Collection and Analysis in Mixed Method Implementation Research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Ecological Role of Water-Column Microbes in the Sea.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from YOLO9000: Better, Faster, Stronger.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Moral Hazard and Observability.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rapid and efficient site-specific mutagenesis without phenotypic selection..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Genome sequence-based species delimitation with confidence intervals and improved distance functions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fronts propagating with curvature-dependent speed: Algorithms based on Hamilton-Jacobi formulations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Two-equation eddy-viscosity turbulence models for engineering applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The International HapMap Project.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rethinking the Inception Architecture for Computer Vision.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Optimization and Approximation in Deterministic Sequencing and Scheduling: a Survey.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Projections of Global Mortality and Burden of Disease from 2002 to 2030.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Amyloid Oligomers Exacerbate Tau Pathology in a Mouse Model of Tauopathy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The complexity of theorem-proving procedures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Biological identifications through DNA barcodes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Speech Acts.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Human Genome Browser at UCSC.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Model-based Analysis of ChIP-Seq (MACS).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Pluripotency of mesenchymal stem cells derived from adult marrow.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The worldwide leaf economics spectrum.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Squeeze-and-Excitation Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Genomic sequencing..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Sequencing technologies — the next generation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The mutational constraint spectrum quantified from variation in 141,456 humans.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Decision-Making in a Fuzzy Environment.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Alternative to Compactification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Human Adipose Tissue Is a Source of Multipotent Stem Cells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ff14SB: Improving the Accuracy of Protein Side Chain and Backbone Parameters from ff99SB.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from New Developments in Molecular Orbital Theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ultrahigh electron mobility in suspended graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Partial Differential Equations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Golden Eggs and Hyperbolic Discounting.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Correspondence of the brain's functional architecture during activation and rest.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Semiconductor Clusters, Nanocrystals, and Quantum Dots.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Building Theories from Case Study Research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrative genomics viewer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Apparent hydroxyl radical production by peroxynitrite: implications for endothelial injury from nitric oxide and superoxide..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Phonons and related crystal properties from density-functional perturbation theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mathematical model for studying genetic variation in terms of restriction endonucleases..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from clusterProfiler: an R Package for Comparing Biological Themes Among Gene Clusters.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Orality and Literacy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Power failure: why small sample size undermines the reliability of neuroscience.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inferring tumour purity and stromal and immune cell admixture from expression data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Note on an Approximation Treatment for Many-Electron Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Co-creation experiences: The next practice in value creation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Design and synthesis of an exceptionally stable and highly porous metal-organic framework.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Full-length transcriptome assembly from RNA-Seq data without a reference genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from tRNAscan-SE: A Program for Improved Detection of Transfer RNA Genes in Genomic Sequence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A fast quantum mechanical algorithm for database search.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Using the framework method for the analysis of qualitative data in multi-disciplinary health research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A method for obtaining digital signatures and public-key cryptosystems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Tight control of gene expression in mammalian cells by tetracycline-responsive promoters..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Revealing Noncovalent Interactions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Effect of National Culture on the Choice of Entry Mode.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Crime and Punishment: An Economic Approach.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Neurons with graded response have collective computational properties like those of two-state neurons..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gradient-based learning applied to document recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Development of the World Health Organization WHOQOL-BREF Quality of Life Assessment.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RAxML-VI-HPC: maximum likelihood-based phylogenetic analyses with thousands of taxa and mixed models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A core gut microbiome in obese and lean twins.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Investigation of the freely available easy-to-use software ‘EZR’ for medical statistics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Survey of Clustering Algorithms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Improving Bioscience Research Reporting: The ARRIVE Guidelines for Reporting Animal Research.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Property Rights and the Nature of the Firm.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Integrative Model Of Organizational Trust.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE WNT SIGNALING PATHWAY IN DEVELOPMENT AND DISEASE.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE ADSORPTION OF GASES ON PLANE SURFACES OF GLASS, MICA AND PLATINUM..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from MotionCor2: anisotropic correction of beam-induced motion for improved cryo-electron microscopy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Macrophage plasticity and polarization: in vivo veritas.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from OrthoMCL: Identification of Ortholog Groups for Eukaryotic Genomes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Canonical sampling through velocity rescaling.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Novel Type of Phase Transition in a System of Self-Driven Particles.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Solutions for a cultivated planet.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Separable dual-space Gaussian pseudopotentials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Foundations of social theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self-Consistent Equations Including Exchange and Correlation Effects.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Second Generation Force Field for the Simulation of Proteins, Nucleic Acids, and Organic Molecules.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A human gut microbial gene catalogue established by metagenomic sequencing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Extremely randomized trees.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A novel gene containing a trinucleotide repeat that is expanded and unstable on Huntington's disease chromosomes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Methylation-specific PCR: a novel PCR assay for methylation status of CpG islands..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Hydrogen-storage materials for mobile applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Speeded-Up Robust Features (SURF).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comprehensive molecular characterization of human colon and rectal cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Identification of Endogenous Social Effects: The Reflection Problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A scalable content-addressable network.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A pneumonia outbreak associated with a new coronavirus of probable bat origin.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inhibited Spontaneous Emission in Solid-State Physics and Electronics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Use of the Hough transformation to detect lines and curves in pictures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ModelFinder: fast model selection for accurate phylogenetic estimates.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dynamic mapping of human cortical development during childhood through early adulthood.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Computational thinking.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On Estimation of a Probability Density Function and Mode.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Particle creation by black holes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The World Health Organization quality of life assessment (WHOQOL): Position paper from the World Health Organization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Stable signal recovery from incomplete and inaccurate measurements.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Elastic Properties of Lipid Bilayers: Theory and Possible Experiments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cochrane Handbook for Systematic Reviews of Interventions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Densely Connected Convolutional Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Relaxation Effects in Nuclear Magnetic Resonance Absorption.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Measuring inconsistency in meta-analyses.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from PD-1 blockade induces responses by inhibiting adaptive immune resistance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Understanding the Warburg Effect: The Metabolic Requirements of Cell Proliferation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Grey Wolf Optimizer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from HISAT: a fast spliced aligner with low memory requirements.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Numerical Heat Transfer and Fluid Flow.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Finding the missing heritability of complex diseases.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Unconventional superconductivity in magic-angle graphene superlattices.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The economic implications of corporate financial reporting.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from High-Speed Tracking with Kernelized Correlation Filters.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The basics of epithelial-mesenchymal transition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CheckM: assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Coefficient alpha and the internal structure of tests.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The International Scientific Association for Probiotics and Prebiotics consensus statement on the scope and appropriate use of the term probiotic.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Computer \"Experiments\" on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Biological insights from 108 schizophrenia-associated genetic loci.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Induction of decision trees.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Model of Growth Through Creative Destruction.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Investment in Human Capital: A Theoretical Analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Black phosphorus field-effect transistors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Angiotensin-converting enzyme 2 is a functional receptor for the SARS coronavirus.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SURF: Speeded Up Robust Features.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Unified Approach for Molecular Dynamics and Density-Functional Theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The 2007 WHO Classification of Tumours of the Central Nervous System.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Are Government Bonds Net Wealth?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Multidrug resistance in cancer: role of ATP–dependent transporters.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from phyloseq: An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Van der Waals heterostructures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Rat Brain in Stereotaxic Coordinates.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Remdesivir and chloroquine effectively inhibit the recently emerged novel coronavirus (2019-nCoV) in vitro.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The weirdest people in the world?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Normalized cuts and image segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An algorithm for the machine calculation of complex Fourier series.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Obesity is associated with macrophage accumulation in adipose tissue.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Membrane lipids: where they are and how they behave.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from node2vec.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Large-Area Synthesis of High-Quality and Uniform Graphene Films on Copper Foils.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Estimating Nonresponse Bias in Mail Surveys.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Large-Scale Video Classification with Convolutional Neural Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Internationalization Process of the Firm—A Model of Knowledge Development and Increasing Foreign Market Commitments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A biomarker that identifies senescent human cells in culture and in aging skin in vivo..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Electron transfers in chemistry and biology.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Diffusion of Innovations in Service Organizations: Systematic Review and Recommendations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The magical number seven, plus or minus two: Some limits on our capacity for processing information..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Alginate: Properties and biomedical applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Image-to-Image Translation with Conditional Adversarial Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GAN（Generative Adversarial Nets）.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The neural basis of drug craving: An incentive-sensitization theory of addiction.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mixed effects models and extensions in ecology with R.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self-efficacy: Toward a unifying theory of behavioral change..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Coherence in Spontaneous Radiation Processes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Factors associated with COVID-19-related death using OpenSAFELY.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bootstrap Methods for Standard Errors, Confidence Intervals, and Other Measures of Statistical Accuracy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Identity Mappings in Deep Residual Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum Spin Hall Insulator State in HgTe Quantum Wells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Finance and Growth: Schumpeter Might Be Right.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The functional anatomy of basal ganglia disorders.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bayesian Analysis of Radiocarbon Dates.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Methods of conjugate gradients for solving linear systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Studies on products of browning reaction. Antioxidative activities of products of browning reaction prepared from glucosamine..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Developing and evaluating complex interventions: the new Medical Research Council guidance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Efficient Graph-Based Image Segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from How Much Should We Trust Differences-In-Differences Estimates?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Apoptosis: A Basic Biological Phenomenon with Wideranging Implications in Tissue Kinetics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rapid isolation of high molecular weight plant DNA.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Second-generation PLINK: rising to the challenge of larger and richer datasets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Adam: A Method for Stochastic Optimization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dynamical Model of Elementary Particles Based on an Analogy with Superconductivity. I.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Recombinant genomes which express chloramphenicol acetyltransferase in mammalian cells..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Does the chimpanzee have a theory of mind?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Digital Natives, Digital Immigrants Part 1.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Acute Kidney Injury Network: report of an initiative to improve outcomes in acute kidney injury.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Perseus computational platform for comprehensive analysis of (prote)omics data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Geant4 developments and applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Neural networks for pattern recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On the limited memory BFGS method for large scale optimization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Visualizing and Understanding Convolutional Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The pyramid of corporate social responsibility: Toward the moral management of organizational stakeholders.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Molecular portraits of human breast tumours.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A map of human genome variation from population-scale sequencing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from LC3, a mammalian homologue of yeast Apg8p, is localized in autophagosome membranes after processing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The PRISMA statement for reporting systematic reviews and meta-analyses of studies that evaluate healthcare interventions: explanation and elaboration.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Two-dimensional gas of massless Dirac fermions in graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mussel-Inspired Surface Chemistry for Multifunctional Coatings.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DADA2: High-resolution sample inference from Illumina amplicon data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Unicycler: Resolving bacterial genome assemblies from short and long sequencing reads.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Studies of interference in serial verbal reactions..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from [19] Rapid and efficient site-specific mutagenesis without phenotypic selection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Robust Estimation of a Location Parameter.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Inquiry into the Nature and Causes of the Wealth of Nations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The species Severe acute respiratory syndrome-related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from p53 Mutations in Human Cancers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mutational landscape determines sensitivity to PD-1 blockade in non–small cell lung cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DAVID: Database for Annotation, Visualization, and Integrated Discovery.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Room-Temperature Ionic Liquids. Solvents for Synthesis and Catalysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from 2015 American Thyroid Association Management Guidelines for Adult Patients with Thyroid Nodules and Differentiated Thyroid Cancer: The American Thyroid Association Guidelines Task Force on Thyroid Nodules and Differentiated Thyroid Cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The plant immune system.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The 2016 World Health Organization Classification of Tumors of the Central Nervous System: a summary.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Consensus Problems in Networks of Agents With Switching Topology and Time-Delays.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Convolutional Neural Networks for Sentence Classification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Molecular mechanisms of epithelial–mesenchymal transition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from U1 snRNP regulates cancer cell migration and invasion in vitro.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Turbulence and the dynamics of coherent structures. I. Coherent structures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self‐determination theory and work motivation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from StringTie enables improved reconstruction of a transcriptome from RNA-seq reads.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Non-local Neural Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Restoring the Density-Gradient Expansion for Exchange in Solids and Surfaces.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Theory of Rational Option Pricing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Relaxed Phylogenetics and Dating with Confidence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The diagnosis of dementia due to Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A general framework for estimating the relative pathogenicity of human genetic variants.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gephi: An Open Source Software for Exploring and Manipulating Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantized Hall Conductance in a Two-Dimensional Periodic Potential.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A global overview of drought and heat-induced tree mortality reveals emerging climate change risks for forests.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A fast and elitist multiobjective genetic algorithm: NSGA-II.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global trends in emerging infectious diseases.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Principles of nanoparticle design for overcoming biological barriers to drug delivery.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Hedonic Prices and Implicit Markets: Product Differentiation in Pure Competition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Updating P300: An integrative theory of P3a and P3b.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from BLEU.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Motivational and self-regulated learning components of classroom academic performance..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The equity premium: A puzzle.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Structure and Function of Complex Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Data Structures for Statistical Computing in Python.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cochrane Collaboration's tool for assessing risk of bias in randomised trials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Central Problems in Social Theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Generalized Gradient Approximation Made Simple [Phys. Rev. Lett. 77, 3865 (1996)].txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Development and validation of a geriatric depression screening scale: A preliminary report.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Definitions for Sepsis and Organ Failure and Guidelines for the Use of Innovative Therapies in Sepsis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Increased Survival in Pancreatic Cancer with nab-Paclitaxel plus Gemcitabine.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Electric Field Effect in Atomically Thin Carbon Films.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mining and summarizing customer reviews.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Normalization of Real-Time Quantitative Reverse Transcription-PCR Data: A Model-Based Variance Estimation Approach to Identify Genes Suited for Normalization, Applied to Bladder and Colon Cancer Data Sets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Government Spending in a Simple Model of Endogeneous Growth.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comprehensive molecular portraits of human breast tumours.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GW170817: Observation of Gravitational Waves from a Binary Neutron Star Inspiral.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from pROC: an open-source package for R and S+ to analyze and compare ROC curves.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Microsoft COCO: Common Objects in Context.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from What To Do (and Not to Do) with Time-Series Cross-Section Data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Efficient Implementation of Weighted ENO Schemes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A review of the source, behaviour and distribution of arsenic in natural waters.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Nominal Rigidities and the Dynamic Effects of a Shock to Monetary Policy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Evidence based medicine: what it is and what it isn't.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A framework for variation discovery and genotyping using next-generation DNA sequencing data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Pascal Visual Object Classes (VOC) Challenge.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Determinants of Perceived Ease of Use: Integrating Control, Intrinsic Motivation, and Emotion into the Technology Acceptance Model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from You Only Look Once: Unified, Real-Time Object Detection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement: Guidelines for Reporting Observational Studies.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Active contours without edges.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Toward defining the preclinical stages of Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inflammation and cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum Dots for Live Cells, in Vivo Imaging, and Diagnostics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Double-slit photoelectron interference in strong-field ionization of the neon dimer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Building a Large Annotated Corpus of English: The Penn Treebank.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Significance of Electromagnetic Potentials in the Quantum Theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The American Joint Committee on Cancer: the 7th Edition of the AJCC Cancer Staging Manual and the Future of TNM.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The diagnosis of mild cognitive impairment due to Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Generating optimal topologies in structural design using a homogenization method.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DeepWalk.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Processable aqueous dispersions of graphene nanosheets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cutadapt removes adapter sequences from high-throughput sequencing reads.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Density-functional method for nonequilibrium electron transport.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Human Domination of Earth's Ecosystems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Increasing Returns and Economic Geography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Selective Search for Object Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Architectural Innovation: The Reconfiguration of Existing Product Technologies and the Failure of Established Firms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A New Equation to Estimate Glomerular Filtration Rate.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Determining Lyapunov exponents from a time series.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Materials for electrochemical capacitors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Situated Learning: Legitimate Peripheral Participation..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Real time quantitative PCR..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Incubation Period of Coronavirus Disease 2019 (COVID-19) From Publicly Reported Confirmed Cases: Estimation and Application.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CHARMM: The biomolecular simulation program.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mixed-Effects Models in Sand S-PLUS.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from In situ click chemistry generation of cyclooxygenase-2 inhibitors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Open Babel: An open chemical toolbox.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quality criteria were proposed for measurement properties of health status questionnaires.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The control of the false discovery rate in multiple testing under dependency.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Scale-space and edge detection using anisotropic diffusion.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The use of the area under the ROC curve in the evaluation of machine learning algorithms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Visible Light Photoredox Catalysis with Transition Metal Complexes: Applications in Organic Synthesis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Using thematic analysis in psychology.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Oxygen toxicity, oxygen radicals, transition metals and disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Salmon provides fast and bias-aware quantification of transcript expression.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from EFFECTS OF BIODIVERSITY ON ECOSYSTEM FUNCTIONING: A CONSENSUS OF CURRENT KNOWLEDGE.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Metallic Phase with Long-Range Orientational Order and No Translational Symmetry.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ImageNet Large Scale Visual Recognition Challenge.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from New Method for Calculating the One-Particle Green's Function with Application to the Electron-Gas Problem.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Lifetime Prevalence of Mental Disorders in U.S. Adolescents: Results from the National Comorbidity Survey Replication–Adolescent Supplement (NCS-A).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GROMACS 4: Algorithms for Highly Efficient, Load-Balanced, and Scalable Molecular Simulation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Qualitative Analysis for Social Scientists.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mersenne twister.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Foodborne Illness Acquired in the United States—Major Pathogens.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Universal Density Profile from Hierarchical Clustering.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Body fat assessed from total body density and its estimation from skinfold thickness: measurements on 481 men and women aged from 16 to 72 Years.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The PRISMA 2020 statement: an updated guideline for reporting systematic reviews.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ultrasensitive fluorescent proteins for imaging neuronal activity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A unified formulation of the constant temperature molecular dynamics methods.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CAP3: A DNA Sequence Assembly Program.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Self-consistent molecular orbital methods. XXIII. A polarization-type basis set for second-row elements.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The global distribution and burden of dengue.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Emerging applications of stimuli-responsive polymer materials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Stem cells, cancer, and cancer stem cells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A study of the conditions and mechanism of the diphenylamine reaction for the colorimetric estimation of deoxyribonucleic acid.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE DISTRIBUTION AND CHEMICAL COMPOSITION OF ULTRACENTRIFUGALLY SEPARATED LIPOPROTEINS IN HUMAN SERUM.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Die Berechnung optischer und elektrostatischer Gitterpotentiale.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An integrated encyclopedia of DNA elements in the human genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Introduction To Compressive Sampling.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FastTree 2 – Approximately Maximum-Likelihood Trees for Large Alignments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from TopHat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast Parallel Algorithms for Short-Range Molecular Dynamics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GMRES: A Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Structure validation in chemical crystallography.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Abstract interpretation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Two-dimensional atomic crystals.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from High-Resolution X-Ray Photoemission Spectrum of the Valence Bands of Gold.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Trace Element Discrimination Diagrams for the Tectonic Interpretation of Granitic Rocks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Qualitative Research: Introducing focus groups.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Attitudinal effects of mere exposure..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Co3O4 nanocrystals on graphene as a synergistic catalyst for oxygen reduction reaction.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Calcium signalling: dynamics, homeostasis and remodelling.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Determinants of corporate borrowing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Polymer Photovoltaic Cells: Enhanced Efficiencies via a Network of Internal Donor-Acceptor Heterojunctions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Phyre2 web portal for protein modeling, prediction and analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FSTAT (Version 1.2): A Computer Program to Calculate F-Statistics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Why Minimal Guidance During Instruction Does Not Work: An Analysis of the Failure of Constructivist, Discovery, Problem-Based, Experiential, and Inquiry-Based Teaching.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from BLAST+: architecture and applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from NONPOINT POLLUTION OF SURFACE WATERS WITH PHOSPHORUS AND NITROGEN.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Linear Models and Empirical Bayes Methods for Assessing Differential Expression in Microarray Experiments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Exceptional chemical and thermal stability of zeolitic imidazolate frameworks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Simplest Systematics for the Organization of Turn-Taking for Conversation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A tutorial on support vector regression.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The FAIR Guiding Principles for scientific data management and stewardship.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Specification Tests in Econometrics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Predictive functional profiling of microbial communities using 16S rRNA marker gene sequences.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Culture of Human Endothelial Cells Derived from Umbilical Veins. IDENTIFICATION BY MORPHOLOGIC AND IMMUNOLOGIC CRITERIA.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CRISPR Provides Acquired Resistance Against Viruses in Prokaryotes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from 2020 ESC Guidelines for the diagnosis and management of atrial fibrillation developed in collaboration with the European Association for Cardio-Thoracic Surgery (EACTS).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Voxel-Based Morphometry—The Methods.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Time, clocks, and the ordering of events in a distributed system.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Thermal properties of graphene and nanostructured carbon materials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mate selection—A selection for a handicap.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On the Theory of Oxidation-Reduction Reactions Involving Electron Transfer. I.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Re-epithelialization and immune cell behaviour in an ex vivo human skin model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The blockade of immune checkpoints in cancer immunotherapy.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Lethality and centrality in protein networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Coordination of groups of mobile autonomous agents using nearest neighbor rules.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Q-learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Metascape provides a biologist-oriented resource for the analysis of systems-level datasets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Scikit-learn: Machine Learning in Python.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The world report on violence and health.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Boron nitride substrates for high-quality graphene electronics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On the Einstein Podolsky Rosen paradox.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from FaceNet: A unified embedding for face recognition and clustering.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Spintronics: Fundamentals and applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Statistical Distribution Function of Wide Applicability.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast approximate energy minimization via graph cuts.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ad-hoc on-demand distance vector routing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Multidimensional binary search trees used for associative searching.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Linear methods in band theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Towards a natural system of organisms: proposal for the domains Archaea, Bacteria, and Eucarya..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ror2 signaling regulates Golgi structure and transport through IFT20 for tumor invasiveness.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Social force model for pedestrian dynamics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Analysis of the genome sequence of the flowering plant Arabidopsis thaliana.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from NIH Image to ImageJ: 25 years of image analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A review of electrode materials for electrochemical supercapacitors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Relationship-based approach to leadership: Development of leader-member exchange (LMX) theory of leadership over 25 years: Applying a multi-level multi-domain perspective.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Construct validity in psychological tests..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A novel assay for apoptosis Flow cytometric detection of phosphatidylserine expression on early apoptotic cells using fluorescein labelled Annexin V.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Superconductivity at 93 K in a new mixed-phase Y-Ba-Cu-O compound system at ambient pressure.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Psychological Safety and Learning Behavior in Work Teams.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Perfect Equilibrium in a Bargaining Model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The moderator–mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Addressing Moderated Mediation Hypotheses: Theory, Methods, and Prescriptions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Scale of Grade and Class Terms for Clastic Sediments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum computation with quantum dots.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The CLUSTAL_X windows interface: flexible strategies for multiple sequence alignment aided by quality analysis tools.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Development of the Colle-Salvetti correlation-energy formula into a functional of the electron density.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fault-tolerant quantum computation by anyons.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The CES-D Scale.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inflationary universe: A possible solution to the horizon and flatness problems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An Introduction to the Five‐Factor Model and Its Applications.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Inhomogeneous Electron Gas.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from RNA-Seq: a revolutionary tool for transcriptomics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Model for a Quantum Hall Effect without Landau Levels: Condensed-Matter Realization of the \"Parity Anomaly\".txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Accurate transcription initiation by RNA polymerase II in a soluble extract from isolated mammalian nuclei.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from EROSIONAL DEVELOPMENT OF STREAMS AND THEIR DRAINAGE BASINS; HYDROPHYSICAL APPROACH TO QUANTITATIVE MORPHOLOGY.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Neurotoxic reactive astrocytes are induced by activated microglia.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from No free lunch theorems for optimization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Implicit social cognition: Attitudes, self-esteem, and stereotypes..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A survey on deep learning in medical image analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Lead Iodide Perovskite Sensitized All-Solid-State Submicron Thin Film Mesoscopic Solar Cell with Efficiency Exceeding 9%.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A vector space model for automatic indexing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Geant4—a simulation toolkit.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from What's wrong with Bonferroni adjustments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Rethinking individualism and collectivism: Evaluation of theoretical assumptions and meta-analyses..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The RAST Server: Rapid Annotations using Subsystems Technology.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from 3D Slicer as an image computing platform for the Quantitative Imaging Network.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Stanford CoreNLP Natural Language Processing Toolkit.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Spurious regressions in econometrics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Confidence Limits for the Indirect Effect: Distribution of the Product and Resampling Methods.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Theory of reproducing kernels.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ultrastructural Characterization of the Lower Motor System in a Mouse Model of Krabbe Disease.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Maintaining knowledge about temporal intervals.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Effect of Word of Mouth on Sales: Online Book Reviews.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Pattern formation outside of equilibrium.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Pharmaceuticals, Hormones, and Other Organic Wastewater Contaminants in U.S. Streams, 1999−2000: A National Reconnaissance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Extra Precision Glide: Docking and Scoring Incorporating a Model of Hydrophobic Enclosure for Protein−Ligand Complexes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Tandem repeats finder: a program to analyze DNA sequences.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ribosomal DNA spacer-length polymorphisms in barley: mendelian inheritance, chromosomal location, and population dynamics..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GRADE: an emerging consensus on rating quality of evidence and strength of recommendations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Simple statistical gradient-following algorithms for connectionist reinforcement learning.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Thresholding of Statistical Maps in Functional Neuroimaging Using the False Discovery Rate.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Exact Matrix Completion via Convex Optimization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Steroid and Thyroid Hormone Receptor Superfamily.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Approximation by superpositions of a sigmoidal function.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Focal Loss for Dense Object Detection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from WGCNA: an R package for weighted correlation network analysis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Frailty in elderly people.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Highly efficient organic light-emitting diodes from delayed fluorescence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Primer3 on the WWW for General Users and for Biologist Programmers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Uncovering the overlapping community structure of complex networks in nature and society.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Economic Growth in a Cross Section of Countries.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Emotional Intelligence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bootstrap Methods: Another Look at the Jackknife.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Comprehensive molecular characterization of gastric adenocarcinoma.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The NRAO VLA Sky Survey.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Chemical Composition of the Sun.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Palladium-Catalyzed Cross-Coupling Reactions of Organoboron Compounds.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from jModelTest 2: more models, new heuristics and parallel computing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Many-body physics with ultracold gases.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Generalized gradient approximation for the exchange-correlation hole of a many-electron system.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Neural Substrate of Prediction and Reward.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from THE CORPORATE SOCIAL PERFORMANCE-FINANCIAL PERFORMANCE LINK.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Reticular synthesis and the design of new materials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Random sample consensus.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Exploring the full spectrum of macrophage activation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from I-TASSER: a unified platform for automated protein structure and function prediction.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Ecological Approach to Visual Perception.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The electronic properties of graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Half a century of research on the Stroop effect: An integrative review..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Transcript assembly and quantification by RNA-Seq reveals unannotated transcripts and isoform switching during cell differentiation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Summary for Policymakers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Power laws, Pareto distributions and Zipf's law.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Maximizing the spread of influence through a social network.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ultrafast and memory-efficient alignment of short DNA sequences to the human genome.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Introduction to Information Retrieval.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Missing data: Our view of the state of the art..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Deciphering the biology of Mycobacterium tuberculosis from the complete genome sequence.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Style-Based Generator Architecture for Generative Adversarial Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Structure of the SARS-CoV-2 spike receptor-binding domain bound to the ACE2 receptor.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Perfect Metamaterial Absorber.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Repeated observation of breast tumor subtypes in independent gene expression data sets.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Ultra-high-throughput microbial community analysis on the Illumina HiSeq and MiSeq platforms.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from U-Net: Convolutional Networks for Biomedical Image Segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Eye movements in reading and information processing: 20 years of research..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Complex thermoelectric materials.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cancer Genome Landscapes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The genetical theory of natural selection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mutations of the BRAF gene in human cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from GSVA: gene set variation analysis for microarray and RNA-Seq data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Graphene: Status and Prospects.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The role of pattern-recognition receptors in innate immunity: update on Toll-like receptors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cultures and Organizations: Software of the Mind..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from World Map of the Köppen-Geiger climate classification updated.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CLUSTAL W: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mixed Methods Research: A Research Paradigm Whose Time Has Come.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from 2012 Revised International Chapel Hill Consensus Conference Nomenclature of Vasculitides.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A new hybrid exchange–correlation functional using the Coulomb-attenuating method (CAM-B3LYP).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Revised American Thyroid Association Management Guidelines for Patients with Thyroid Nodules and Differentiated Thyroid Cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Deep Learning Face Attributes in the Wild.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Energy Band-Gap Engineering of Graphene Nanoribbons.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The SCARE 2020 Guideline: Updating Consensus Surgical CAse REport (SCARE) Guidelines.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Signatures of mutational processes in human cancer.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Least angle regression.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from DNA sequencing with chain-terminating inhibitors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Standardisation of spirometry.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Extinction risk from climate change.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Prospect Theory: An Analysis of Decision under Risk.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Increasing Returns, Path Dependence, and the Study of Politics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from STAR FORMATION IN GALAXIES ALONG THE HUBBLE SEQUENCE.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast, scalable generation of high‐quality protein multiple sequence alignments using Clustal Omega.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Interrater reliability: the kappa statistic.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Prevalence of Childhood and Adult Obesity in the United States, 2011-2012.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Quantum entanglement.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A novel potent vasoconstrictor peptide produced by vascular endothelial cells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from WordNet.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SwissADME: a free web tool to evaluate pharmacokinetics, drug-likeness and medicinal chemistry friendliness of small molecules.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Review of Particle Physics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Unscented Filtering and Nonlinear Estimation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An equilibrium characterization of the term structure.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Red and photographic infrared linear combinations for monitoring vegetation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Dynamic capabilities and strategic management.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrated genomic analyses of ovarian carcinoma.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Projector augmented-wave method.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Risk and protective factors for alcohol and other drug problems in adolescence and early adulthood: Implications for substance abuse prevention..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The NIST definition of cloud computing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Sloan Digital Sky Survey: Technical Summary.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fast model-based estimation of ancestry in unrelated individuals.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The relation of strength of stimulus to rapidity of habit‐formation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Grading quality of evidence and strength of recommendations.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Atomic Force Microscope.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SeaView Version 4: A Multiplatform Graphical User Interface for Sequence Alignment and Phylogenetic Tree Building.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CBAM: Convolutional Block Attention Module.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SLIC Superpixels Compared to State-of-the-Art Superpixel Methods.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Applied Logistic Regression.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from On Information and Sufficiency.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global analyses of sea surface temperature, sea ice, and night marine air temperature since the late nineteenth century.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from An integrated map of genetic variation from 1,092 human genomes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from 3D Convolutional Neural Networks for Human Action Recognition.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Composite Medium with Simultaneously Negative Permeability and Permittivity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from UK Biobank: An Open Access Resource for Identifying the Causes of a Wide Range of Complex Diseases of Middle and Old Age.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bad is Stronger than Good.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bidirectional recurrent neural networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The PRISMA Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Health Care Interventions: Explanation and Elaboration.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Knowledge and Teaching:Foundations of the New Reform.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Occurrence of the potent mutagens 2- nitrobenzanthrone and 3-nitrobenzanthrone in fine airborne particles.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from What Good Are Positive Emotions?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrative Genomics Viewer (IGV): high-performance genomics data visualization and exploration.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Saturation in qualitative research: exploring its conceptualization and operationalization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Virological assessment of hospitalized patients with COVID-2019.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Additive logistic regression: a statistical view of boosting (With discussion and a rejoinder by the authors).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from BEAST: Bayesian evolutionary analysis by sampling trees.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Global, regional, and national prevalence of overweight and obesity in children and adults during 1980–2013: a systematic analysis for the Global Burden of Disease Study 2013.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Sub-diffraction-limit imaging by stochastic optical reconstruction microscopy (STORM).txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Synthesis of Transportation Fuels from Biomass: Chemistry, Catalysts, and Engineering.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Representation Learning: A Review and New Perspectives.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Neural networks and physical systems with emergent collective computational abilities..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Confirmation Bias: A Ubiquitous Phenomenon in Many Guises.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Circos: An information aesthetic for comparative genomics.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fingerprinting genomes using PCR with arbitrary primers.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Tissue Cells Feel and Respond to the Stiffness of Their Substrate.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Phosphorene: An Unexplored 2D Semiconductor with a High Hole Mobility.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from SciPy 1.0: fundamental algorithms for scientific computing in Python.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Teleporting an unknown quantum state via dual classical and Einstein-Podolsky-Rosen channels.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Raman spectroscopy as a versatile tool for studying the properties of graphene.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Support-vector networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Genome sequencing in microfabricated high-density picolitre reactors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrative analysis of 111 reference human epigenomes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gmsh: A 3‐D finite element mesh generator with built‐in pre‐ and post‐processing facilities.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Management ownership and market valuation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Pyramid Scene Parsing Network.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Histograms of Oriented Gradients for Human Detection.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Perceptual Losses for Real-Time Style Transfer and Super-Resolution.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Cancer Cell Line Encyclopedia enables predictive modelling of anticancer drug sensitivity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Amino acid substitution matrices from protein blocks..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from What Will 5G Be?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from PYTHIA 6.4 physics and manual.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Theory of Superconductivity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Improved tools for biological sequence comparison..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Artificial intelligence: a modern approach.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A method for the solution of certain non-linear problems in least squares.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Stellar population synthesis at the resolution of 2003.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Improved adsorption energetics within density-functional theory using revised Perdew-Burke-Ernzerhof functionals.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A simple technique for quantitation of low levels of DNA damage in individual cells.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from QUAST: quality assessment tool for genome assemblies.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Van der Waals Density Functional for General Geometries.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Optical Properties and Electronic Structure of Amorphous Germanium.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from High-yield production of graphene by liquid-phase exfoliation of graphite.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Machine learning in automated text categorization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Survey of Corporate Governance.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Bank Runs, Deposit Insurance, and Liquidity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from IntCal13 and Marine13 Radiocarbon Age Calibration Curves 0–50,000 Years cal BP.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Functional connectivity in the resting brain: A network analysis of the default mode hypothesis.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Survey of Augmented Reality.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from QIIME allows analysis of high-throughput community sequencing data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Error and attack tolerance of complex networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Swin Transformer: Hierarchical Vision Transformer using Shifted Windows.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Statistical mechanics of complex networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Software survey: VOSviewer, a computer program for bibliometric mapping.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A performance evaluation of local descriptors.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The Proof and Measurement of Association between Two Things.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Development of recommendations for SEMG sensors and sensor placement procedures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Graph-Based Algorithms for Boolean Function Manipulation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Integrative Analysis of Complex Cancer Genomics and Clinical Profiles Using the cBioPortal.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Cluster analysis and display of genome-wide expression patterns.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Gauge theory correlators from non-critical string theory.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Data clustering.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Image Super-Resolution Using Deep Convolutional Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A Simple Model of Herd Behavior.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Independent component analysis, A new concept?.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from The NumPy Array: A Structure for Efficient Numerical Computation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Aggregation-induced emission.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from First principles methods using CASTEP.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A view of cloud computing.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from CDK inhibitors: positive and negative regulators of G1-phase progression.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Food in the Anthropocene: the EAT–Lancet Commission on healthy diets from sustainable food systems.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Negative Refraction Makes a Perfect Lens.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Differential expression analysis for sequence count data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Plasma perspective on strong field multiphoton ionization.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Fully convolutional networks for semantic segmentation.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Loss Aversion in Riskless Choice: A Reference-Dependent Model.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Mediation in experimental and nonexperimental studies: New procedures and recommendations..txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Design and Analysis of Computer Experiments.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Measurement of Diversity.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A scaling normalization method for differential expression analysis of RNA-seq data.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Learning Spatiotemporal Features with 3D Convolutional Networks.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from A biochemical model of photosynthetic CO2 assimilation in leaves of C3 species.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Topological domains in mammalian genomes identified by analysis of chromatin interactions.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Estimating and Testing Linear Models with Multiple Structural Changes.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from MOLSCRIPT: a program to produce both detailed and schematic plots of protein structures.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "reading data from Food-Related Illness and Death in the United States.txt...\n",
      "string successfully retrieved.\n",
      "\n",
      "22560.497492477432\n"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "for paper in os.listdir(\"../text\"):\n",
    "    text = get_string_from_text_file(paper)\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    length = len(tokenizer.encode(str))\n",
    "    hist.append(length)\n",
    "print(sum(hist) / len(hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../vector_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant.lib.llm import LLM, test\n",
    "import tiktoken\n",
    "import re\n",
    "import json\n",
    "import openai\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../code\")\n",
    "from util import extract_pdf_to_txt, extract_doi_to_txt, get_string_from_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(target: str, model: str = \"gpt-4\"):\n",
    "    tokenizer = tiktoken.encoding_for_model(model)\n",
    "    return len(tokenizer.encode(target))\n",
    "\n",
    "\n",
    "def handle_exception(e: Exception, log_file_path: str):\n",
    "    print(\"Exception occurred during execution. aborting\")\n",
    "    print(e)\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(\"\\nAborted due to exception during execution. Error:\\n\")\n",
    "        f.write(str(e))\n",
    "    return False, str(e), \"***ERROR DURING EXECUTION***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_llm(\n",
    "    paper_txt_path: str = \"../text/3D Convolutional Neural Networks for Human Action Recognition.txt\",\n",
    "    model: str = \"gpt-4\",\n",
    ") -> tuple[bool, str, str]:\n",
    "    # load text\n",
    "    system_prompt = get_string_from_text_file(\"../prompts/llm_prompt.txt\")\n",
    "    paper_data = get_string_from_text_file(paper_txt_path)\n",
    "    # make prompt\n",
    "    prompt = system_prompt + paper_data + \"\\n```\\n\"\n",
    "\n",
    "    # get response from gpt\n",
    "    llm = LLM(\n",
    "        base=\"azure\",\n",
    "        use_model=\"gpt4\" if model == \"gpt-4\" else \"gpt3\",\n",
    "    )\n",
    "    msgs = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        # {\"role\": \"user\", \"content\": \"hi give me a response in json\"},\n",
    "    ]\n",
    "    responses = []\n",
    "\n",
    "    LOG_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/log\"\n",
    "    RESULT_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/results\"\n",
    "    idx = len(os.listdir(LOG_DIR))\n",
    "    result_file_name = paper_txt_path.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "    output_log_file_path = os.path.join(LOG_DIR, f\"LOG-{idx}_{result_file_name}.log\")\n",
    "    output_result_file_path = os.path.join(RESULT_DIR, result_file_name + \".json\")\n",
    "    total_input_token, total_output_token = 0, 0\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\"Paper title: {result_file_name}\")\n",
    "    print(f\"Paper contains {count_tokens(paper_data,model=model)} tokens\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            llm.set_prompt(prompt=msgs)\n",
    "            response, finish_reason, usage = llm.get_response(\n",
    "                max_tokens=4096,\n",
    "                # max_tokens=100,\n",
    "                response_format=\"text\",\n",
    "                # response_format=\"json_object\",\n",
    "                is_custom=True,\n",
    "            )\n",
    "            # write log\n",
    "            with open(output_log_file_path, \"a\") as f:\n",
    "                f.write(response)\n",
    "                f.write(f\"\\n\\nfinish reason: {finish_reason}\")\n",
    "                f.write(f\"\\ntoken usage{str(usage)}\")\n",
    "                f.write(\"\\n=======================================\\n\")\n",
    "\n",
    "            print(\"Tokens used:\", usage, \"Finish reason:\", finish_reason)\n",
    "            responses.append(response.replace(\"\\n\", \" \"))\n",
    "            total_input_token += usage.prompt_tokens\n",
    "            total_output_token += usage.completion_tokens\n",
    "            if finish_reason == \"stop\":\n",
    "                break\n",
    "            elif finish_reason == \"length\":\n",
    "                msgs.append({\"role\": \"assistant\", \"content\": response})\n",
    "                msgs.append(\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"Your response was cut off. Please CONTINUE FROM WHERE YOU STOPPED. Your response will be appended to your previous response, and thus it should be a continuation of your previous response. Because it is a continuation, your response may not be in JSON format. However, note that the final result (all your responses added up) need to be in JSON format (This is important). Refer to the output format to see where you left off. You will be penalized for starting your response from the beginning, or outputting inconsistent responses\",\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    \"Finish reason of gpt response needs to be checked. Finish reason:\",\n",
    "                    finish_reason,\n",
    "                )\n",
    "    except Exception as e:\n",
    "        return handle_exception(e, output_log_file_path)\n",
    "\n",
    "    print(f\"{len(responses)} API calls\")\n",
    "    final_response = \"\".join(responses)\n",
    "    num_tokens = count_tokens(final_response, model=model)\n",
    "    print(f\"final response is {num_tokens} tokens\")\n",
    "    print(f\"Total input tokens used:{total_input_token}\")\n",
    "    print(f\"Total output tokens used:{total_output_token}\")\n",
    "    # check if valid json\n",
    "    try:\n",
    "        final_response = re.findall(r\"\\{.*\\}\", final_response, re.DOTALL)[0]\n",
    "        json.loads(final_response)\n",
    "    except Exception as e:\n",
    "        is_valid_json = False\n",
    "        return handle_exception(e, output_log_file_path)\n",
    "    else:\n",
    "        is_valid_json = True\n",
    "    # is_valid_json = type(json.loads(final_response)) is dict\n",
    "    print(f\"Is valid json: {is_valid_json}\")\n",
    "    with open(\"../gpt_response.txt\", \"w\") as file:\n",
    "        # file.write(response)\n",
    "        file.write(final_response)\n",
    "\n",
    "    # return response\n",
    "    with open(output_log_file_path, \"a\") as f:\n",
    "        f.write(f\"\\n\\nFINAL RESPONSE ({num_tokens} tokens):\\n\")\n",
    "        f.write(final_response)\n",
    "        f.write(f\"\\n\\nTotal input tokens:{total_input_token}\")\n",
    "        f.write(f\"\\nTotal output tokens:{total_output_token}\")\n",
    "        f.write(f\"\\nIs valid JSON:{is_valid_json}\")\n",
    "        f.write(f\"\\nTime elapsed: {time.time()-start_time}\")\n",
    "    with open(output_result_file_path, \"w\") as f:\n",
    "        f.write(final_response)\n",
    "    return True, \"-\", final_response\n",
    "\n",
    "\n",
    "# is_pass, e, res = apply_llm()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"filename\": \"3D Convolutional Neural Networks for Human Action Recognition\",\n",
      "    \"extracted-section-list\": [\n",
      "        \"Introduction\",\n",
      "        \"3D Convolutional Neural Networks\",\n",
      "        \"Related Work\",\n",
      "        \"Experiments\",\n",
      "        \"Conclusions and Discussions\"\n",
      "    ],\n",
      "    \"target-section-extraction-result\": {\n",
      "        \"introduction\": \"Recognizing human actions in real-world environment\\n\\u00ads applications in a variety of domains including in-\\ntelligent video surveillance, customer attributes, and\\nshopping behavior analysis. However, accurate recog-\\nnition of actions is a highly challenging task due to\\nAppearing in Proceedings of the 27thInternational Confer-\\nence on Machine Learning , Haifa, Israel, 2010. Copyright\\n2010 by the author(s)/owner(s).cluttered backgrounds, occlusions, and viewpoint vari-\\nations, etc. Therefore, most of the existing approaches\\n(Efros et al. ,2003;Sch\\u0308 uldt et al. ,2004;Doll\\u0301 ar et al. ,\\n2005;Laptev & P\\u0301 erez ,2007;Jhuang et al. ,2007)\\nmake certain assumptions (e.g., small scale and view-\\npoint changes) about the circumstances under which\\nthe video was taken. However, such assumptions sel-\\ndom hold in real-world environment. In addition, most\\nof these approaches follow the conventional paradigm\\nof pattern recognition, which consists of two steps in\\nwhich the \\u00adrst step computes complex handcrafted fea-\\ntures from raw video frames and the second step learns\\nclassi\\u00aders based on the obtained features. In real-world\\nscenarios, it is rarely known which features are impor-\\ntant for the task at hand, since the choice of feature is\\nhighly problem-dependent. Especially for human ac-\\ntion recognition, di\\u00e2erent action classes may appear\\ndramatically di\\u00e2erent in terms of their appearances\\nand motion patterns.\\nDeep learning models ( Fukushima ,1980;LeCun et al. ,\\n1998;Hinton & Salakhutdinov ,2006;Hinton et al. ,\\n2006;Bengio ,2009) are a class of machines that can\\nlearn a hierarchy of features by building high-level\\nfeatures from low-level ones, thereby automating the\\nprocess of feature construction. Such learning ma-\\nchines can be trained using either supervised or un-\\nsupervised approaches, and the resulting systems have\\nbeen shown to yield competitive performance in visual\\nobject recognition ( LeCun et al. ,1998;Hinton et al. ,\\n2006;Ranzato et al. ,2007;Lee et al. ,2009a), natu-\\nral language processing ( Collobert & Weston ,2008),\\nand audio classi\\u00adcation ( Lee et al. ,2009b ) tasks. The\\nconvolutional neural networks (CNNs) ( LeCun et al. ,\\n1998) are a type of deep models in which trainable\\n\\u00adlters and local neighborhood pooling operations are\\napplied alternatingly on the raw input images, result-\\ning in a hierarchy of increasingly complex features.\\nIt has been shown that, when trained with appropri-3D Convolutional Neural Networks for Human Action Recognit ion\\nate regularization ( Ahmed et al. ,2008;Yu et al. ,2008;\\nMobahi et al. ,2009), CNNs can achieve superior per-\\nformance on visual object recognition tasks without\\nrelying on handcrafted features. In addition, CNNs\\nhave been shown to be relatively insensitive to certain\\nvariations on the inputs ( LeCun et al. ,2004).\\nAs a class of attractive deep models for automated fea-\\nture construction, CNNs have been primarily applied\\non 2D images. In this paper, we consider the use of\\nCNNs for human action recognition in videos. A sim-\\nple approach in this direction is to treat video frames\\nas still images and apply CNNs to recognize actions\\nat the individual frame level. Indeed, this approach\\nhas been used to analyze the videos of developing\\nembryos ( Ning et al. ,2005). However, such approach\\ndoes not consider the motion information encoded in\\nmultiple contiguous frames. To e\\u00aeectively incorporate\\nthe motion information in video analysis, we propose\\nto perform 3D convolution in the convolutional layers\\nof CNNs so that discriminative features along both\\nspatial and temporal dimensions are captured. We\\nshow that by applying multiple distinct convolutional\\noperations at the same location on the input, multi-\\nple types of features can be extracted. Based on the\\nproposed 3D convolution, a variety of 3D CNN archi-\\ntectures can be devised to analyze video data. We\\ndevelop a 3D CNN architecture that generates multi-\\nple channels of information from adjacent video frames\\nand performs convolution and subsampling separately\\nin each channel. The \\u00adnal feature representation is\\nobtained by combining information from all channels.\\nAn additional advantage of the CNN-based models is\\nthat the recognition phase is very e\\u00b3cient due to their\\nfeed-forward nature.\\nWe evaluated the developed 3D CNN model on the\\nTREC Video Retrieval Evaluation (TRECVID) data1,\\nwhich consist of surveillance video data recorded in\\nLondon Gatwick Airport. We constructed a multi-\\nmodule event detection system, which includes 3D\\nCNN as a module, and participated in three tasks of\\nthe TRECVID 2009 Evaluation for Surveillance Event\\nDetection. Our system achieved the best performance\\non all three participated tasks. To provide indepen-\\ndent evaluation of the 3D CNN model, we report its\\nperformance on the TRECVID 2008 development set\\nin this paper. We also present results on the KTH\\ndata as published performance for this data is avail-\\nable. Our experiments show that the developed 3D\\nCNN model outperforms other baseline methods on\\nthe TRECVID data, and it achieves competitive per-\\nformance on the KTH data without depending on\\n1http://www-nlpir.nist.gov/projects/trecvid/handcrafted features, demonstrating that the 3D CNN\\nmodel is more e\\u00aeective for real-world environments\\nsuch as those captured in TRECVID data. The exper-\\niments also show that the 3D CNN model signi\\u00adcantly\\noutperforms the frame-based 2D CNN for most tasks.\\nWe also observe that the performance di\\u00aeerences be-\\ntween 3D CNN and other methods tend to be larger\\nwhen the number of positive training samples is small.\",\n",
      "        \"method\": \"In 2D CNNs, 2D convolution is performed at the con-\\nvolutional layers to extract features from local neigh-\\nborhood on feature maps in the previous layer. Then\\nan additive bias is applied and the result is passed\\nthrough a sigmoid function. Formally, the value of\\nunit at position ( x, y) in the jth feature map in the\\nith layer, denoted as vxy\\nij, is given by\\nvxy\\nij= tanh(\\nbij+\\u2211\\nmPi\\u22121\\u2211\\np=0Qi\\u22121\\u2211\\nq=0wpq\\nijmv(x+p)(y+q)\\n(i\\u22121)m)\\n,\\n(1)\\nwhere tanh( \\u00b7) is the hyperbolic tangent function, bij\\nis the bias for this feature map, mindexes over the\\nset of feature maps in the ( i\\u22121)th layer connected\\nto the current feature map, wpq\\nijkis the value at the\\nposition ( p, q) of the kernel connected to the kth fea-\\nture map, and PiandQiare the height and width\\nof the kernel, respectively. In the subsampling lay-\\ners, the resolution of the feature maps is reduced by\\npooling over local neighborhood on the feature maps\\nin the previous layer, thereby increasing invariance to\\ndistortions on the inputs. A CNN architecture can be\\nconstructed by stacking multiple layers of convolution\\nand subsampling in an alternating fashion. The pa-\\nrameters of CNN, such as the bias bijand the kernel\\nweight wpq\\nijk, are usually trained using either super-\\nvised or unsupervised approaches ( LeCun et al. ,1998;\\nRanzato et al. ,2007).\\n2.1. 3D Convolution\\nIn 2D CNNs, convolutions are applied on the 2D fea-\\nture maps to compute features from the spatial dimen-\\nsions only. When applied to video analysis problems,\\nit is desirable to capture the motion information en-\\ncoded in multiple contiguous frames. To this end, we\\npropose to perform 3D convolutions in the convolution\\nstages of CNNs to compute features from both spa-\\ntial and temporal dimensions. The 3D convolution is\\nachieved by convolving a 3D kernel to the cube formed\\nby stacking multiple contiguous frames together. By\\nthis construction, the feature maps in the convolution\\nlayer is connected to multiple contiguous frames in the3D Convolutional Neural Networks for Human Action Recognit ion\\n(a) 2D convolution\\nt\\ne\\nm\\np\\no\\nr\\na\\nl\\n(b) 3D convolution\\nFigure 1. Comparison of 2D (a) and 3D (b) convolutions.\\nIn (b) the size of the convolution kernel in the temporal\\ndimension is 3, and the sets of connections are color-coded\\nso that the shared weights are in the same color. In 3D\\nconvolution, the same 3D kernel is applied to overlapping\\n3D cubes in the input video to extract motion features.\\nprevious layer, thereby capturing motion information.\\nFormally, the value at position ( x, y, z ) on the jth fea-\\nture map in the ith layer is given by\\nvxyz\\nij=tanh(\\nbij+\\u2211\\nmPi\\u22121\\u2211\\np=0Qi\\u22121\\u2211\\nq=0Ri\\u22121\\u2211\\nr=0wpqr\\nijmv(x+p)(y+q)(z+r)\\n(i\\u22121)m)\\n,\\n(2)\\nwhere Riis the size of the 3D kernel along the tem-\\nporal dimension, wpqr\\nijmis the ( p, q, r)th value of the\\nkernel connected to the mth feature map in the previ-\\nous layer. A comparison of 2D and 3D convolutions is\\ngiven in Figure 1.\\nNote that a 3D convolutional kernel can only extract\\none type of features from the frame cube, since the\\nkernel weights are replicated across the entire cube. A\\ngeneral design principle of CNNs is that the number\\nof feature maps should be increased in late layers by\\ngenerating multiple types of features from the samet\\ne\\nm\\np\\no\\nr\\na\\nl\\nFigure 2. Extraction of multiple features from contiguous\\nframes. Multiple 3D convolutions can be applied to con-\\ntiguous frames to extract multiple features. As in Figure 1,\\nthe sets of connections are color-coded so that the shared\\nweights are in the same color. Note that all the 6 sets of\\nconnections do not share weights, resulting in two di\\u00e2erent\\nfeature maps on the right.\\nset of lower-level feature maps. Similar to the case\\nof 2D convolution, this can be achieved by applying\\nmultiple 3D convolutions with distinct kernels to the\\nsame location in the previous layer (Figure 2).\\n2.2. A 3D CNN Architecture\\nBased on the 3D convolution described above, a variety\\nof CNN architectures can be devised. In the following,\\nwe describe a 3D CNN architecture that we have devel-\\noped for human action recognition on the TRECVID\\ndata set. In this architecture shown in Figure 3, we\\nconsider 7 frames of size 60 \\u00d740 centered on the current\\nframe as inputs to the 3D CNN model. We \\u00adrst apply a\\nset of hardwired kernels to generate multiple channels\\nof information from the input frames. This results in\\n33 feature maps in the second layer in 5 di\\u00e2erent chan-\\nnels known as gray, gradient-x, gradient-y, opt\\u00e2ow-x,\\nand opt\\u00e2ow-y. The gray channel contains the gray\\npixel values of the 7 input frames. The feature maps\\nin the gradient-x and gradient-y channels are obtained\\nby computing gradients along the horizontal and ver-\\ntical directions, respectively, on each of the 7 input\\nframes, and the opt\\u00e2ow-x and opt\\u00e2ow-y channels con-\\ntain the optical \\u00e2ow \\u00adelds, along the horizontal and\\nvertical directions, respectively, computed from adja-\\ncent input frames. This hardwired layer is used to en-\\ncode our prior knowledge on features, and this scheme\\nusually leads to better performance as compared to\\nrandom initialization.3D Convolutional Neural Networks for Human Action Recognit ion\\nH1:\\n33@60x40\\nC2:\\n23*2@54x34\\n7x7x3 3D\\nconvolution\\n2x2\\nsubsampling\\nS3:\\n23*2@27x17\\n7x6x3 3D\\nconvolution\\nC4:\\n13*6@21x12\\n3x3\\nsubsampling\\nS5:\\n13*6@7x4\\n7x4\\nconvolution\\nC6:\\n128@1x1\\nfull\\nconnnection\\nhardwired\\ninput:\\n7@60x40\\nFigure 3. A 3D CNN architecture for human action recognition. This arc hitecture consists of 1 hardwired layer, 3 convo-\\nlution layers, 2 subsampling layers, and 1 full connection l ayer. Detailed descriptions are given in the text.\\nWe then apply 3D convolutions with a kernel size of\\n7\\u00d77\\u00d73 (7\\u00d77 in the spatial dimension and 3 in the\\ntemporal dimension) on each of the 5 channels sepa-\\nrately. To increase the number of feature maps, two\\nsets of di\\u00e2erent convolutions are applied at each loca-\\ntion, resulting in 2 sets of feature maps in the C2 layer\\neach consisting of 23 feature maps. This layer con-\\ntains 1,480 trainable parameters. In the subsequent\\nsubsampling layer S3, we apply 2 \\u00d72 subsampling on\\neach of the feature maps in the C2 layer, which leads\\nto the same number of feature maps with reduced spa-\\ntial resolution. The number of trainable parameters in\\nthis layer is 92. The next convolution layer C4 is ob-\\ntained by applying 3D convolution with a kernel size\\nof 7\\u00d76\\u00d73 on each of the 5 channels in the two sets\\nof feature maps separately. To increase the number\\nof feature maps, we apply 3 convolutions with di\\u00e2er-\\nent kernels at each location, leading to 6 distinct sets\\nof feature maps in the C4 layer each containing 13\\nfeature maps. This layer contains 3,810 trainable pa-\\nrameters. The next layer S5 is obtained by applying\\n3\\u00d73 subsampling on each feature maps in the C4 layer,\\nwhich leads to the same number of feature maps with\\nreduced spatial resolution. The number of trainable\\nparameters in this layer is 156. At this stage, the size\\nof the temporal dimension is already relatively small\\n(3 for gray, gradient-x, gradient-y and 2 for opt\\u00e2ow-x\\nand opt\\u00e2ow-y), so we perform convolution only in the\\nspatial dimension at this layer. The size of the con-\\nvolution kernel used is 7 \\u00d74 so that the sizes of the\\noutput feature maps are reduced to 1 \\u00d71. The C6 layer\\nconsists of 128 feature maps of size 1 \\u00d71, and each of\\nthem is connected to all the 78 feature maps in the S5\\nlayer, leading to 289,536 trainable parameters.\\nBy the multiple layers of convolution and subsampling,the 7 input frames have been converted into a 128D\\nfeature vector capturing the motion information in the\\ninput frames. The output layer consists of the same\\nnumber of units as the number of actions, and each\\nunit is fully connected to each of the 128 units in\\nthe C6 layer. In this design we essentially apply a\\nlinear classi\\u00ader on the 128D feature vector for action\\nclassi\\u00adcation. For an action recognition problem with\\n3 classes, the number of trainable parameters at the\\noutput layer is 384. The total number of trainable\\nparameters in this 3D CNN model is 295,458, and all\\nof them are initialized randomly and trained by on-\\nline error back-propagation algorithm as described in\\n(LeCun et al. ,1998). We have designed and evalu-\\nated other 3D CNN architectures that combine mul-\\ntiple channels of information at di\\u00e2erent stages, and\\nour results show that this architecture gives the best\\nperformance.\",\n",
      "        \"result\": \"We perform experiments on the TRECVID 2008 data\\nand the KTH data ( Sch\\u0308 uldt et al. ,2004) to evaluate\\nthe developed 3D CNN model for action recognition.\\n4.1. Action Recognition on TRECVID Data\\nThe TRECVID 2008 development data set consists of\\n49-hour videos captured at the London Gatwick Air-\\nport using 5 di\\u00e2erent cameras with a resolution of\\n720\\u00d7576 at 25 fps. The videos recorded by camera\\nnumber 4 are excluded as few events occurred in this\\nscene. In this experiments, we focus on the recognitionof 3 action classes ( CellToEar ,ObjectPut , andPoint-\\ning). Each action is classi\\u00aded in the one-against-rest\\nmanner, and a large number of negative samples were\\ngenerated from actions that are not in these 3 classes.\\nThis data set was captured on \\u00adve days (20071101,\\n20071106, 20071107, 20071108, and 20071112), and\\nthe statistics of the data used in our experiments are\\nsummarized in Table 1. The 3D CNN model used in\\nthis experiment is as described in Section 2and Figure\\n3, and the number of training iterations are tuned on\\na separate validation set.\\nAs the videos were recorded in real-world environ-\\nments, and each frame contains multiple humans, we\\napply a human detector and a detection-driven tracker\\nto locate human heads. Some sample human detec-\\ntion and tracking results are shown in Figure 4. Based\\non the detection and tracking results, a bounding box\\nfor each human that performs action was computed.\\nThe multiple frames required by 3D CNN model are\\nobtained by extracting bounding boxes at the same\\nposition from consecutive frames before and after the\\ncurrent frame, leading to a cube containing the ac-\\ntion. The temporal dimension of the cube is set to\\n7 in our experiments as it has been shown that 5-7\\nframes are enough to achieve a performance similar\\nto the one obtainable with the entire video sequence\\n(Schindler & Van Gool ,2008). The frames were ex-\\ntracted with a step size of 2. That is, suppose the\\ncurrent frame is numbered 0, we extract a bounding\\nbox at the same position from frames numbered -6, -4,\\n-2, 0, 2, 4, and 6. The patch inside the bounding box\\non each frame is scaled to 60 \\u00d740 pixels.\\nTo evaluate the e\\u00aeectiveness of the 3D CNN model, we\\nreport the results of the frame-based 2D CNN model.\\nIn addition, we compare the 3D CNN model with two\\nother baseline methods, which follow the state-of-the-\\nart bag-of-words (BoW) paradigm in which complex\\nhandcrafted features are computed. For each image\\ncube as used in 3D CNN, we construct a BoW feature\\nbased on dense local invariant features. Then a one-3D Convolutional Neural Networks for Human Action Recognit ion\\nagainst-all linear SVM is learned for each action class.\\nSpeci\\u00adcally, we extract dense SIFT descriptors ( Lowe,\\n2004) from raw gray images or motion edge history\\nimages (MEHI) ( Yang et al. ,2009). Local features on\\nraw gray images preserve the appearance information,\\nwhile MEHI concerns with the shape and motion pat-\\nterns. These SIFT descriptors are calculated every 6\\npixels from 7 \\u00d77 and 16 \\u00d716 local image patches in the\\nsame cubes as in the 3D CNN model. Then they are\\nsoftly quantized using a 512-word codebook to build\\nthe BoW features. To exploit the spatial layout in-\\nformation, we employ similar approach as the spatial\\npyramid matching (SPM) ( Lazebnik et al. ,2006) to\\npartition the candidate region into 2 \\u00d72 and 3 \\u00d74 cells\\nand concatenate their BoW features. The dimension-\\nality of the entire feature vector is 512 \\u00d7(2\\u00d72+3\\u00d74) =\\n8192. We denote the method based on gray images as\\nSPMcube\\ngreyand the one based on MEHI as SPMcube\\nMEHI.\\nWe report the 5-fold cross-validation results in which\\nthe data for a single day are used as a fold. The per-\\nformance measures we used are precision, recall, and\\narea under the ROC curve (ACU) at multiple values of\\nfalse positive rates (FPR). The performance of the four\\nmethods is summarized in Table 2. We can observe\\nfrom Table 2that the 3D CNN model outperforms the\\nframe-based 2D CNN model, SPMcube\\ngrey, and SPMcube\\nMEHI\\nsigni\\u00adcantly on the action classes CellToEar andOb-\\njectPut in all cases. For the action class Pointing , 3D\\nCNN model achieves slightly worse performance than\\nthe other three methods. From Table 1we can see that\\nthe number of positive samples in the Pointing class is\\nsigni\\u00adcantly larger than those of the other two classes.\\nHence, we can conclude that the 3D CNN model is\\nmore e\\u00aeective when the number of positive samples is\\nsmall. Overall, the 3D CNN model outperforms other\\nthree methods consistently as can be seen from the\\naverage performance in Table 2.\\n4.2. Action Recognition on KTH Data\\nWe evaluate the 3D CNN model on the KTH data\\n(Sch\\u0308 uldt et al. ,2004), which consist of 6 action classes\\nperformed by 25 subjects. To follow the setup in the\\nHMAX model, we use a 9-frame cube as input and ex-\\ntract foreground as in ( Jhuang et al. ,2007). To reduce\\nthe memory requirement, the resolutions of the input\\nframes are reduced to 80 \\u00d760 in our experiments as\\ncompared to 160 \\u00d7120 used in ( Jhuang et al. ,2007).\\nWe use a similar 3D CNN architecture as in Figure\\n3with the sizes of kernels and the number of feature\\nmaps in each layer modi\\u00adcations to consider the 80 \\u00d760\\u00d79\\ninputs. In particular, the three convolutional layers\\nuse kernels of sizes 9 \\u00d77, 7\\u00d77, and 6 \\u00d74, respec-\\ntively, and the two subsampling layers use kernels of\\nsize 3 \\u00d73. By using this setting, the 80 \\u00d760\\u00d79 in-\\nputs are converted into 128D feature vectors. The \\u00adnal\\nlayer consists of 6 units corresponding to the 6 classes.\\nAs in ( Jhuang et al. ,2007), we use the data for 16 ran-\\ndomly selected subjects for training, and the data for\\nthe other 9 subjects for testing. The recognition per-\\nformance averaged across 5 random trials is reported\\nin Table 3along with published results in the litera-\\nture. The 3D CNN model achieves an overall accu-\\nracy of 90.2% as compared with 91.7% achieved by\\nthe HMAX model. Note that the HMAX model use\\nhandcrafted features computed from raw images with\\n4-fold higher resolution.\",\n",
      "        \"conclusion\": \"We developed a 3D CNN model for action recognition\\nin this paper. This model construct features from both\\nspatial and temporal dimensions by performing 3D\\nconvolutions. The developed deep architecture gener-\\nates multiple channels of information from adjacent in-\\nput frames and perform convolution and subsampling\\nseparately in each channel. The \\u00adnal feature represen-\\ntation is computed by combining information from all\\nchannels. We evaluated the 3D CNN model using the\\nTRECVID and the KTH data sets. Results show that\\nthe 3D CNN model outperforms compared methods\\non the TRECVID data, while it achieves competitive\\nperformance on the KTH data, demonstrating its su-\\nperior performance in real-world environments.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\n",
    "    \"/Users/ms/cs/ML/MLab/paper-extraction/results/3D Convolutional Neural Networks for Human Action Recognition.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    print(json.dumps(json.load(f), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Paper title: A frameshift mutation in NOD2 associated with susceptibility to Crohn's disease\n",
      "Paper contains 8874 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Updated world map of the Köppen-Geiger climate classification\n",
      "Paper contains 15311 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 51 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: A safe operating space for humanity\n",
      "Paper contains 7425 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Mutation in the α-Synuclein Gene Identified in Families with Parkinson's Disease\n",
      "Paper contains 6715 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Capacity of Multi‐antenna Gaussian Channels\n",
      "Paper contains 70492 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 56 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Instrumental Variables Regression with Weak Instruments\n",
      "Paper contains 0 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: A Self-Rating Depression Scale\n",
      "Paper contains 36839 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The representative concentration pathways: an overview\n",
      "Paper contains 22977 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Random effects structure for confirmatory hypothesis testing: Keep it maximal\n",
      "Paper contains 30237 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Homeostasis model assessment: insulin resistance and ?-cell function from fasting plasma glucose and insulin concentrations in man\n",
      "Paper contains 9638 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Gene expression profiling predicts clinical outcome of breast cancer\n",
      "Paper contains 76080 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: A comparison of methods to test mediation and other intervening variable effects.\n",
      "Paper contains 23713 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Opinion Mining and Sentiment Analysis\n",
      "Paper contains 70416 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\n",
      "Paper contains 28291 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Term-weighting approaches in automatic text retrieval\n",
      "Paper contains 0 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 50 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Technology Acceptance Model 3 and a Research Agenda on Interventions\n",
      "Paper contains 30368 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 51 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization\n",
      "Paper contains 26724 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The Graph Neural Network Model\n",
      "Paper contains 26006 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The human brain is intrinsically organized into dynamic, anticorrelated functional networks\n",
      "Paper contains 9328 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: AFLP: a new technique for DNA fingerprinting\n",
      "Paper contains 13234 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Tight blood pressure control and risk of macrovascular and microvascular complications in type 2 diabetes: UKPDS 38\n",
      "Paper contains 17596 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer\n",
      "Paper contains 23761 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: DNA methylation patterns and epigenetic memory\n",
      "Paper contains 26689 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: General Theory of Three-Dimensional Consolidation\n",
      "Paper contains 9016 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The Elements of Statistical Learning\n",
      "Paper contains 10734 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Orthonormal bases of compactly supported wavelets\n",
      "Paper contains 14796 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Diamond-like amorphous carbon\n",
      "Paper contains 7230 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Decoding by Linear Programming\n",
      "Paper contains 12764 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Most mammalian mRNAs are conserved targets of microRNAs\n",
      "Paper contains 20827 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Transformation of the Nitrogen Cycle: Recent Trends, Questions, and Potential Solutions\n",
      "Paper contains 8989 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Cytoscape: A Software Environment for Integrated Models of Biomolecular Interaction Networks\n",
      "Paper contains 8976 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix\n",
      "Paper contains 0 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Ground State of the Electron Gas by a Stochastic Method\n",
      "Paper contains 4723 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Political Science and the Three New Institutionalisms\n",
      "Paper contains 18500 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Mathematical Methods of Classical Mechanics\n",
      "Paper contains 2487 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 53 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Fast and robust fixed-point algorithms for independent component analysis\n",
      "Paper contains 11660 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Five Misunderstandings About Case-Study Research\n",
      "Paper contains 16114 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Association of glycaemia with macrovascular and microvascular complications of type 2 diabetes (UKPDS 35): prospective observational study\n",
      "Paper contains 13438 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Learning Deep Features for Discriminative Localization\n",
      "Paper contains 10674 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Telling more than we can know: Verbal reports on mental processes.\n",
      "Paper contains 30430 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The Benefits of Frequent Positive Affect: Does Happiness Lead to Success?\n",
      "Paper contains 79793 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: The Health Belief Model: A Decade Later\n",
      "Paper contains 25283 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: REVIGO Summarizes and Visualizes Long Lists of Gene Ontology Terms\n",
      "Paper contains 8191 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Translating the Histone Code\n",
      "Paper contains 13731 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Quantum Spin Hall Effect and Topological Phase Transition in HgTe Quantum Wells\n",
      "Paper contains 10865 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Thumbs up?\n",
      "Paper contains 9788 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Speech recognition with deep recurrent neural networks\n",
      "Paper contains 6194 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: UMAP: Uniform Manifold Approximation and Projection\n",
      "Paper contains 551 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Independent component analysis: algorithms and applications\n",
      "Paper contains 22564 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "----------------------------------------------\n",
      "Paper title: Integrating single-cell transcriptomic data across different conditions, technologies, and species\n",
      "Paper contains 20733 tokens\n",
      "Exception occurred during execution. aborting\n",
      "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n",
      "Extraction Result: Fail\n",
      "===== result =====\n",
      "Passed: 0\n",
      "Failed: 50\n",
      "Skipped: 0\n"
     ]
    }
   ],
   "source": [
    "from util import list_to_text_file, get_string_from_text_file\n",
    "\n",
    "TEXT_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/text\"\n",
    "NOTEBOOK_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/notebook\"\n",
    "evaluation_list_filepath = os.path.join(NOTEBOOK_DIR, \"llm_extraction_paper_list.txt\")\n",
    "exception_list_filepath = os.path.join(\n",
    "    NOTEBOOK_DIR, \"llm_extraction_paper_exception_list.txt\"\n",
    ")\n",
    "evaluation_list = get_string_from_text_file(evaluation_list_filepath).splitlines()\n",
    "exception_list = get_string_from_text_file(exception_list_filepath).splitlines()\n",
    "evaluation_list = [paper for paper in evaluation_list if paper not in exception_list]\n",
    "\n",
    "\n",
    "pass_cnt = 0\n",
    "fail_cnt = 0\n",
    "skip_cnt = 0\n",
    "MAX_NUM_OF_PAPERS_FOR_EVAL = 50\n",
    "# erase extraction paper list if you want to restart\n",
    "for paper in os.listdir(TEXT_DIR):\n",
    "    if (pass_cnt + fail_cnt + skip_cnt) >= MAX_NUM_OF_PAPERS_FOR_EVAL:\n",
    "        print(\"===== result =====\")\n",
    "        print(f\"Passed: {pass_cnt}\")\n",
    "        print(f\"Failed: {fail_cnt}\")\n",
    "        print(f\"Skipped: {skip_cnt}\")\n",
    "        break\n",
    "\n",
    "    if paper in evaluation_list or paper in exception_list:\n",
    "        print(f\"Skipping as paper in evaluation/exception list. \\nPaper: {paper}\\n\")\n",
    "        skip_cnt += 1\n",
    "        continue\n",
    "\n",
    "    is_pass, e, res = apply_llm(paper_txt_path=paper)\n",
    "    print(\"Extraction Result:\", \"Pass\" if is_pass else \"Fail\")\n",
    "    if is_pass:\n",
    "        evaluation_list.append(paper)\n",
    "        pass_cnt += 1\n",
    "    else:\n",
    "        exception_list.append(paper)\n",
    "        fail_cnt += 1\n",
    "\n",
    "list_to_text_file(evaluation_list, evaluation_list_filepath)\n",
    "list_to_text_file(exception_list, exception_list_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results on google drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from typing import Literal\n",
    "\n",
    "# connect to the service account\n",
    "gc = gspread.service_account(filename=\"../creds.json\")\n",
    "sh = gc.open(\"Paper Extraction v2\")\n",
    "# sh1 = sh.get_worksheet(0)\n",
    "sh2 = sh.get_worksheet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_update_batch(\n",
    "    batch_list_file_name: str = \"../evaluation_paper_list\",\n",
    "    extraction_method: Literal[\"regex\", \"llm\"] = \"llm\",\n",
    "    start_row_num: int = 4,\n",
    "    sheet=sh2,\n",
    "):\n",
    "    JSON_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/results\"\n",
    "    # get paper list\n",
    "    # papers = get_string_from_text_file(batch_list_file_name).splitlines()\n",
    "    # exception_list = get_string_from_text_file(\n",
    "    # \"../evaluation_paper_exception_list.txt\"\n",
    "    # ).splitlines()\n",
    "    values = []\n",
    "    results = os.listdir(JSON_DIR)\n",
    "    # print(len(results))\n",
    "    for filename in results:\n",
    "        # if filename in exception_list:\n",
    "        #     continue\n",
    "        # content = get_string_from_text_file(filename)\n",
    "        # res = extract(content, filename, extraction_method)\n",
    "\n",
    "        with open(os.path.join(JSON_DIR, filename), \"r\") as f:\n",
    "            res = json.load(f)\n",
    "        temp = res[\"target-section-extraction-result\"]\n",
    "        values.append(\n",
    "            [\n",
    "                res[\"filename\"],\n",
    "                \"\\n\".join(res[\"extracted-section-list\"]),\n",
    "                temp[\"introduction\"],\n",
    "                len(temp[\"introduction\"]),\n",
    "                len(temp[\"introduction\"].split()),\n",
    "                \"null\",\n",
    "                temp[\"method\"],\n",
    "                len(temp[\"method\"]),\n",
    "                len(temp[\"method\"].split()),\n",
    "                \"null\",\n",
    "                temp[\"result\"],\n",
    "                len(temp[\"result\"]),\n",
    "                len(temp[\"result\"].split()),\n",
    "                \"null\",\n",
    "                temp[\"conclusion\"],\n",
    "                len(temp[\"conclusion\"]),\n",
    "                len(temp[\"conclusion\"].split()),\n",
    "                \"null\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    sheet.batch_update(\n",
    "        [\n",
    "            {\n",
    "                \"range\": f\"A{start_row_num}:R{start_row_num-1+len(results)}\",\n",
    "                \"values\": values,\n",
    "            }\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_update_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token number for papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15551"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/Users/ms/cs/ML/MLab/paper-extraction/text/Advances in functional and structural MR image analysis and implementation as FSL.txt\"\n",
    "token_num = len(tokenizer.encode(get_string_from_text_file(file_path)))\n",
    "token_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frameshift mutation in NOD2 associated with susceptibility to Crohn's disease.txt\n",
      "8874\n",
      "Updated world map of the Köppen-Geiger climate classification.txt\n",
      "15311\n",
      "A safe operating space for humanity.txt\n",
      "7425\n",
      "Mutation in the α-Synuclein Gene Identified in Families with Parkinson's Disease.txt\n",
      "6715\n",
      "Capacity of Multi‐antenna Gaussian Channels.txt\n",
      "70492\n",
      "Instrumental Variables Regression with Weak Instruments.txt\n",
      "0\n",
      "A Self-Rating Depression Scale.txt\n",
      "36839\n",
      "The representative concentration pathways: an overview.txt\n",
      "22977\n",
      "Random effects structure for confirmatory hypothesis testing: Keep it maximal.txt\n",
      "30237\n",
      "Homeostasis model assessment: insulin resistance and ?-cell function from fasting plasma glucose and insulin concentrations in man.txt\n",
      "9638\n",
      "Gene expression profiling predicts clinical outcome of breast cancer.txt\n",
      "76080\n",
      "A comparison of methods to test mediation and other intervening variable effects..txt\n",
      "23713\n",
      "Opinion Mining and Sentiment Analysis.txt\n",
      "70416\n",
      "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation.txt\n",
      "28291\n",
      "Term-weighting approaches in automatic text retrieval.txt\n",
      "0\n",
      "Technology Acceptance Model 3 and a Research Agenda on Interventions.txt\n",
      "30368\n",
      "Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization.txt\n",
      "26724\n",
      "The Graph Neural Network Model.txt\n",
      "26006\n",
      "The human brain is intrinsically organized into dynamic, anticorrelated functional networks.txt\n",
      "9328\n",
      "AFLP: a new technique for DNA fingerprinting.txt\n",
      "13234\n"
     ]
    }
   ],
   "source": [
    "TEXT_DIR = \"/Users/ms/cs/ML/MLab/paper-extraction/text\"\n",
    "cnt = 0\n",
    "max = 20\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "for paper in os.listdir(TEXT_DIR):\n",
    "    print(paper)\n",
    "    token_num = len(tokenizer.encode(get_string_from_text_file(paper)))\n",
    "    print(token_num)\n",
    "    # apply_llm(paper_txt_path=paper)\n",
    "    cnt += 1\n",
    "    if cnt >= max:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
